{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "-G6H6HsRTFLn",
      "metadata": {
        "id": "-G6H6HsRTFLn"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/AI4Finance-Foundation/FinRL-Tutorials/blob/master/1-Introduction/China_A_share_market_tushare.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ShYRMdBTFLp",
      "metadata": {
        "id": "3ShYRMdBTFLp"
      },
      "source": [
        "## Quantitative trading in China A stock market with FinRL"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pBU3DdPFTFLp",
      "metadata": {
        "id": "pBU3DdPFTFLp"
      },
      "source": [
        "Install FinRL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51W37k2_TFLq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51W37k2_TFLq",
        "outputId": "e2a8c994-6587-40c0-e166-e33bda9fc958"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wrds in /usr/local/lib/python3.11/site-packages (3.3.0)\n",
            "Requirement already satisfied: packaging<=24.2 in /usr/local/lib/python3.11/site-packages (from wrds) (24.2)\n",
            "Requirement already satisfied: pandas<2.3,>=2.2 in /usr/local/lib/python3.11/site-packages (from wrds) (2.2.3)\n",
            "Requirement already satisfied: psycopg2-binary<2.10,>=2.9 in /usr/local/lib/python3.11/site-packages (from wrds) (2.9.10)\n",
            "Requirement already satisfied: sqlalchemy<2.1,>=2 in /usr/local/lib/python3.11/site-packages (from wrds) (2.0.40)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/site-packages (from pandas<2.3,>=2.2->wrds) (2.2.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/site-packages (from pandas<2.3,>=2.2->wrds) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/site-packages (from pandas<2.3,>=2.2->wrds) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/site-packages (from pandas<2.3,>=2.2->wrds) (2025.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/site-packages (from sqlalchemy<2.1,>=2->wrds) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/site-packages (from sqlalchemy<2.1,>=2->wrds) (4.13.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas<2.3,>=2.2->wrds) (1.17.0)\n",
            "Collecting swig\n",
            "  Using cached swig-4.3.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (3.5 kB)\n",
            "Using cached swig-4.3.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.9 MB)\n",
            "Installing collected packages: swig\n",
            "Successfully installed swig-4.3.0\n",
            "‚ú®üç∞‚ú® Everything looks OK!\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Collecting git+https://github.com/AI4Finance-Foundation/FinRL.git\n",
            "  Cloning https://github.com/AI4Finance-Foundation/FinRL.git to /tmp/pip-req-build-4dawhmau\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/AI4Finance-Foundation/FinRL.git /tmp/pip-req-build-4dawhmau\n",
            "  Resolved https://github.com/AI4Finance-Foundation/FinRL.git to commit d25d902a6de54931a329adc38a2663e8f576adc4\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git (from finrl==0.3.8)\n",
            "  Cloning https://github.com/AI4Finance-Foundation/ElegantRL.git to /tmp/pip-install-443d003p/elegantrl_6668d816008b4d4e9e9e7c6544836457\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/AI4Finance-Foundation/ElegantRL.git /tmp/pip-install-443d003p/elegantrl_6668d816008b4d4e9e9e7c6544836457\n",
            "  Resolved https://github.com/AI4Finance-Foundation/ElegantRL.git to commit 5e828af1503098f4da046c0f12432dbd4ef8bd97\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: alpaca-py<0.38,>=0.37 in /usr/local/lib/python3.11/site-packages (from finrl==0.3.8) (0.37.0)\n",
            "Requirement already satisfied: alpaca-trade-api<4,>=3 in /usr/local/lib/python3.11/site-packages (from finrl==0.3.8) (3.2.0)\n",
            "Requirement already satisfied: ccxt<4,>=3 in /usr/local/lib/python3.11/site-packages (from finrl==0.3.8) (3.1.60)\n",
            "Requirement already satisfied: jqdatasdk<2,>=1 in /usr/local/lib/python3.11/site-packages (from finrl==0.3.8) (1.9.7)\n",
            "Requirement already satisfied: pyfolio-reloaded<0.10,>=0.9 in /usr/local/lib/python3.11/site-packages (from finrl==0.3.8) (0.9.8)\n",
            "Requirement already satisfied: pyportfolioopt<2,>=1 in /usr/local/lib/python3.11/site-packages (from finrl==0.3.8) (1.5.6)\n",
            "Requirement already satisfied: ray<3,>=2 in /usr/local/lib/python3.11/site-packages (from ray[default,tune]<3,>=2->finrl==0.3.8) (2.44.1)\n",
            "Requirement already satisfied: scikit-learn<2,>=1 in /usr/local/lib/python3.11/site-packages (from finrl==0.3.8) (1.6.1)\n",
            "Requirement already satisfied: selenium<5,>=4 in /usr/local/lib/python3.11/site-packages (from finrl==0.3.8) (4.31.0)\n",
            "Requirement already satisfied: stable-baselines3>=2.0.0a5 in /usr/local/lib/python3.11/site-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (2.6.0)\n",
            "Requirement already satisfied: stockstats<0.6,>=0.5 in /usr/local/lib/python3.11/site-packages (from finrl==0.3.8) (0.5.4)\n",
            "Requirement already satisfied: webdriver-manager<5,>=4 in /usr/local/lib/python3.11/site-packages (from finrl==0.3.8) (4.0.2)\n",
            "Requirement already satisfied: wrds<4,>=3 in /usr/local/lib/python3.11/site-packages (from finrl==0.3.8) (3.3.0)\n",
            "Requirement already satisfied: yfinance<0.3,>=0.2 in /usr/local/lib/python3.11/site-packages (from finrl==0.3.8) (0.2.55)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.3 in /usr/local/lib/python3.11/site-packages (from alpaca-py<0.38,>=0.37->finrl==0.3.8) (1.0.3)\n",
            "Requirement already satisfied: pandas>=1.5.3 in /usr/local/lib/python3.11/site-packages (from alpaca-py<0.38,>=0.37->finrl==0.3.8) (2.2.3)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.3 in /usr/local/lib/python3.11/site-packages (from alpaca-py<0.38,>=0.37->finrl==0.3.8) (2.11.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.30.0 in /usr/local/lib/python3.11/site-packages (from alpaca-py<0.38,>=0.37->finrl==0.3.8) (2.32.3)\n",
            "Requirement already satisfied: sseclient-py<2.0.0,>=1.7.2 in /usr/local/lib/python3.11/site-packages (from alpaca-py<0.38,>=0.37->finrl==0.3.8) (1.8.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/site-packages (from alpaca-py<0.38,>=0.37->finrl==0.3.8) (10.4)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.11/site-packages (from alpaca-trade-api<4,>=3->finrl==0.3.8) (2.2.4)\n",
            "Requirement already satisfied: urllib3<2,>1.24 in /usr/local/lib/python3.11/site-packages (from alpaca-trade-api<4,>=3->finrl==0.3.8) (1.26.20)\n",
            "Requirement already satisfied: websocket-client<2,>=0.56.0 in /usr/local/lib/python3.11/site-packages (from alpaca-trade-api<4,>=3->finrl==0.3.8) (1.8.0)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.3 in /usr/local/lib/python3.11/site-packages (from alpaca-trade-api<4,>=3->finrl==0.3.8) (3.11.16)\n",
            "Requirement already satisfied: PyYAML==6.0.1 in /usr/local/lib/python3.11/site-packages (from alpaca-trade-api<4,>=3->finrl==0.3.8) (6.0.1)\n",
            "Requirement already satisfied: deprecation==2.1.0 in /usr/local/lib/python3.11/site-packages (from alpaca-trade-api<4,>=3->finrl==0.3.8) (2.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/site-packages (from deprecation==2.1.0->alpaca-trade-api<4,>=3->finrl==0.3.8) (24.2)\n",
            "Requirement already satisfied: setuptools>=60.9.0 in /usr/local/lib/python3.11/site-packages (from ccxt<4,>=3->finrl==0.3.8) (65.6.3)\n",
            "Requirement already satisfied: certifi>=2018.1.18 in /usr/local/lib/python3.11/site-packages (from ccxt<4,>=3->finrl==0.3.8) (2024.12.14)\n",
            "Requirement already satisfied: cryptography>=2.6.1 in /usr/local/lib/python3.11/site-packages (from ccxt<4,>=3->finrl==0.3.8) (44.0.2)\n",
            "Requirement already satisfied: aiodns>=1.1.1 in /usr/local/lib/python3.11/site-packages (from ccxt<4,>=3->finrl==0.3.8) (3.2.0)\n",
            "Requirement already satisfied: yarl>=1.7.2 in /usr/local/lib/python3.11/site-packages (from ccxt<4,>=3->finrl==0.3.8) (1.19.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/site-packages (from jqdatasdk<2,>=1->finrl==0.3.8) (1.17.0)\n",
            "Requirement already satisfied: SQLAlchemy>=1.2.8 in /usr/local/lib/python3.11/site-packages (from jqdatasdk<2,>=1->finrl==0.3.8) (2.0.40)\n",
            "Requirement already satisfied: pymysql>=0.7.6 in /usr/local/lib/python3.11/site-packages (from jqdatasdk<2,>=1->finrl==0.3.8) (1.1.1)\n",
            "Requirement already satisfied: thriftpy2!=0.5.1,>=0.3.9 in /usr/local/lib/python3.11/site-packages (from jqdatasdk<2,>=1->finrl==0.3.8) (0.5.2)\n",
            "Requirement already satisfied: ipython>=3.2.3 in /usr/local/lib/python3.11/site-packages (from pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (9.1.0)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.11/site-packages (from pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (3.10.1)\n",
            "Requirement already satisfied: pytz>=2014.10 in /usr/local/lib/python3.11/site-packages (from pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (2025.2)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.11/site-packages (from pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (1.15.2)\n",
            "Requirement already satisfied: seaborn>=0.7.1 in /usr/local/lib/python3.11/site-packages (from pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (0.13.2)\n",
            "Requirement already satisfied: empyrical-reloaded>=0.5.9 in /usr/local/lib/python3.11/site-packages (from pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (0.5.11)\n",
            "Requirement already satisfied: cvxpy>=1.1.19 in /usr/local/lib/python3.11/site-packages (from pyportfolioopt<2,>=1->finrl==0.3.8) (1.6.5)\n",
            "Requirement already satisfied: ecos<3.0.0,>=2.0.14 in /usr/local/lib/python3.11/site-packages (from pyportfolioopt<2,>=1->finrl==0.3.8) (2.0.14)\n",
            "Requirement already satisfied: plotly<6.0.0,>=5.0.0 in /usr/local/lib/python3.11/site-packages (from pyportfolioopt<2,>=1->finrl==0.3.8) (5.24.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/site-packages (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.8) (8.1.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.8) (3.18.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/site-packages (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.8) (4.23.0)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.11/site-packages (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.8) (6.30.2)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.11/site-packages (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.8) (1.3.2)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.11/site-packages (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.8) (1.5.0)\n",
            "Requirement already satisfied: aiohttp_cors in /usr/local/lib/python3.11/site-packages (from ray[default,tune]<3,>=2->finrl==0.3.8) (0.8.1)\n",
            "Requirement already satisfied: colorful in /usr/local/lib/python3.11/site-packages (from ray[default,tune]<3,>=2->finrl==0.3.8) (0.5.6)\n",
            "Requirement already satisfied: py-spy>=0.2.0 in /usr/local/lib/python3.11/site-packages (from ray[default,tune]<3,>=2->finrl==0.3.8) (0.4.0)\n",
            "Requirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.11/site-packages (from ray[default,tune]<3,>=2->finrl==0.3.8) (1.71.0)\n",
            "Requirement already satisfied: opencensus in /usr/local/lib/python3.11/site-packages (from ray[default,tune]<3,>=2->finrl==0.3.8) (0.11.4)\n",
            "Requirement already satisfied: prometheus_client>=0.7.1 in /usr/local/lib/python3.11/site-packages (from ray[default,tune]<3,>=2->finrl==0.3.8) (0.21.1)\n",
            "Requirement already satisfied: smart_open in /usr/local/lib/python3.11/site-packages (from ray[default,tune]<3,>=2->finrl==0.3.8) (7.1.0)\n",
            "Requirement already satisfied: virtualenv!=20.21.1,>=20.0.24 in /usr/local/lib/python3.11/site-packages (from ray[default,tune]<3,>=2->finrl==0.3.8) (20.30.0)\n",
            "Requirement already satisfied: tensorboardX>=1.9 in /usr/local/lib/python3.11/site-packages (from ray[default,tune]<3,>=2->finrl==0.3.8) (2.6.2.2)\n",
            "Requirement already satisfied: pyarrow>=9.0.0 in /usr/local/lib/python3.11/site-packages (from ray[default,tune]<3,>=2->finrl==0.3.8) (19.0.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/site-packages (from ray[default,tune]<3,>=2->finrl==0.3.8) (2025.3.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/site-packages (from scikit-learn<2,>=1->finrl==0.3.8) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/site-packages (from scikit-learn<2,>=1->finrl==0.3.8) (3.6.0)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.11/site-packages (from selenium<5,>=4->finrl==0.3.8) (0.29.0)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.11/site-packages (from selenium<5,>=4->finrl==0.3.8) (0.12.2)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.11/site-packages (from selenium<5,>=4->finrl==0.3.8) (4.13.2)\n",
            "Requirement already satisfied: gymnasium<1.2.0,>=0.29.1 in /usr/local/lib/python3.11/site-packages (from stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (1.1.1)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/site-packages (from stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (2.6.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/site-packages (from stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (3.1.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/site-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (4.11.0.86)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.11/site-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (2.6.1)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.11/site-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (2.19.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/site-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (7.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/site-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (4.67.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/site-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (14.0.0)\n",
            "Requirement already satisfied: ale-py>=0.9.0 in /usr/local/lib/python3.11/site-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (0.10.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/site-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (11.2.1)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/site-packages (from webdriver-manager<5,>=4->finrl==0.3.8) (1.1.0)\n",
            "Requirement already satisfied: psycopg2-binary<2.10,>=2.9 in /usr/local/lib/python3.11/site-packages (from wrds<4,>=3->finrl==0.3.8) (2.9.10)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.11/site-packages (from yfinance<0.3,>=0.2->finrl==0.3.8) (0.0.11)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.11/site-packages (from yfinance<0.3,>=0.2->finrl==0.3.8) (4.3.6)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.11/site-packages (from yfinance<0.3,>=0.2->finrl==0.3.8) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.11/site-packages (from yfinance<0.3,>=0.2->finrl==0.3.8) (3.17.3)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.11/site-packages (from yfinance<0.3,>=0.2->finrl==0.3.8) (4.13.3)\n",
            "Requirement already satisfied: th in /usr/local/lib/python3.11/site-packages (from elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git->finrl==0.3.8) (0.4.1)\n",
            "Requirement already satisfied: pycares>=4.0.0 in /usr/local/lib/python3.11/site-packages (from aiodns>=1.1.1->ccxt<4,>=3->finrl==0.3.8) (4.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/site-packages (from aiohttp<4,>=3.8.3->alpaca-trade-api<4,>=3->finrl==0.3.8) (2.6.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/site-packages (from aiohttp<4,>=3.8.3->alpaca-trade-api<4,>=3->finrl==0.3.8) (25.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/site-packages (from aiohttp<4,>=3.8.3->alpaca-trade-api<4,>=3->finrl==0.3.8) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/site-packages (from aiohttp<4,>=3.8.3->alpaca-trade-api<4,>=3->finrl==0.3.8) (0.3.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/site-packages (from beautifulsoup4>=4.11.1->yfinance<0.3,>=0.2->finrl==0.3.8) (2.6)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/site-packages (from cryptography>=2.6.1->ccxt<4,>=3->finrl==0.3.8) (1.17.1)\n",
            "Requirement already satisfied: osqp>=0.6.2 in /usr/local/lib/python3.11/site-packages (from cvxpy>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.8) (1.0.3)\n",
            "Requirement already satisfied: clarabel>=0.5.0 in /usr/local/lib/python3.11/site-packages (from cvxpy>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.8) (0.10.0)\n",
            "Requirement already satisfied: scs>=3.2.4.post1 in /usr/local/lib/python3.11/site-packages (from cvxpy>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.8) (3.2.7.post2)\n",
            "Requirement already satisfied: bottleneck>=1.3.0 in /usr/local/lib/python3.11/site-packages (from empyrical-reloaded>=0.5.9->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (1.4.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/site-packages (from gymnasium<1.2.0,>=0.29.1->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (0.0.4)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/site-packages (from ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (5.2.1)\n",
            "Requirement already satisfied: ipython-pygments-lexers in /usr/local/lib/python3.11/site-packages (from ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (1.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/site-packages (from ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (0.19.2)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/site-packages (from ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/site-packages (from ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (4.9.0)\n",
            "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /usr/local/lib/python3.11/site-packages (from ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (3.0.50)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.11/site-packages (from ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (2.19.1)\n",
            "Requirement already satisfied: stack_data in /usr/local/lib/python3.11/site-packages (from ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (0.6.3)\n",
            "Requirement already satisfied: traitlets>=5.13.0 in /usr/local/lib/python3.11/site-packages (from ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (5.14.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/site-packages (from matplotlib>=1.4.0->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/site-packages (from matplotlib>=1.4.0->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/site-packages (from matplotlib>=1.4.0->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/site-packages (from matplotlib>=1.4.0->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/site-packages (from matplotlib>=1.4.0->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/site-packages (from matplotlib>=1.4.0->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/site-packages (from pandas>=1.5.3->alpaca-py<0.38,>=0.37->finrl==0.3.8) (2025.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/site-packages (from plotly<6.0.0,>=5.0.0->pyportfolioopt<2,>=1->finrl==0.3.8) (9.1.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.0.3->alpaca-py<0.38,>=0.37->finrl==0.3.8) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.0.3->alpaca-py<0.38,>=0.37->finrl==0.3.8) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.0.3->alpaca-py<0.38,>=0.37->finrl==0.3.8) (0.4.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests<3.0.0,>=2.30.0->alpaca-py<0.38,>=0.37->finrl==0.3.8) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests<3.0.0,>=2.30.0->alpaca-py<0.38,>=0.37->finrl==0.3.8) (3.10)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/site-packages (from SQLAlchemy>=1.2.8->jqdatasdk<2,>=1->finrl==0.3.8) (3.1.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (2.2.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (3.1.3)\n",
            "Requirement already satisfied: Cython>=3.0.10 in /usr/local/lib/python3.11/site-packages (from thriftpy2!=0.5.1,>=0.3.9->jqdatasdk<2,>=1->finrl==0.3.8) (3.0.12)\n",
            "Requirement already satisfied: ply<4.0,>=3.4 in /usr/local/lib/python3.11/site-packages (from thriftpy2!=0.5.1,>=0.3.9->jqdatasdk<2,>=1->finrl==0.3.8) (3.11)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/site-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (1.3.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/site-packages (from trio~=0.17->selenium<5,>=4->finrl==0.3.8) (2.4.0)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.11/site-packages (from trio~=0.17->selenium<5,>=4->finrl==0.3.8) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/site-packages (from trio~=0.17->selenium<5,>=4->finrl==0.3.8) (1.3.1)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.11/site-packages (from trio-websocket~=0.9->selenium<5,>=4->finrl==0.3.8) (1.2.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/site-packages (from urllib3[socks]<3,>=1.26->selenium<5,>=4->finrl==0.3.8) (1.7.1)\n",
            "Requirement already satisfied: distlib<1,>=0.3.7 in /usr/local/lib/python3.11/site-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<3,>=2->finrl==0.3.8) (0.3.9)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/site-packages (from jsonschema->ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.8) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/site-packages (from jsonschema->ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.8) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/site-packages (from jsonschema->ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.8) (0.24.0)\n",
            "Requirement already satisfied: opencensus-context>=0.1.3 in /usr/local/lib/python3.11/site-packages (from opencensus->ray[default,tune]<3,>=2->finrl==0.3.8) (0.1.3)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.11/site-packages (from opencensus->ray[default,tune]<3,>=2->finrl==0.3.8) (2.24.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/site-packages (from rich->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (3.0.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/site-packages (from smart_open->ray[default,tune]<3,>=2->finrl==0.3.8) (1.17.2)\n",
            "Requirement already satisfied: niltype<2.0,>=0.3 in /usr/local/lib/python3.11/site-packages (from th->elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git->finrl==0.3.8) (1.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/site-packages (from cffi>=1.12->cryptography>=2.6.1->ccxt<4,>=3->finrl==0.3.8) (2.22)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.8) (1.70.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.8) (1.26.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.8) (2.39.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/site-packages (from jedi>=0.16->ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (0.8.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (0.1.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/site-packages (from pexpect>4.3->ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (0.2.13)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (3.0.2)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium<5,>=4->finrl==0.3.8) (0.14.0)\n",
            "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.11/site-packages (from stack_data->ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (2.2.0)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.11/site-packages (from stack_data->ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (3.0.0)\n",
            "Requirement already satisfied: pure-eval in /usr/local/lib/python3.11/site-packages (from stack_data->ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8) (0.2.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/site-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.8) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/site-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.8) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/site-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.8) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.8) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install wrds\n",
        "!pip install swig\n",
        "%pip install trading_calendars\n",
        "%pip install pandas_market_calendars akshare gym zipline-reloaded pyfolio\n",
        "# !pip install -q condacolab\n",
        "# import condacolab\n",
        "# condacolab.install()\n",
        "!apt-get update -y -qq && apt-get install -y -qq cmake libopenmpi-dev python3-dev zlib1g-dev libgl1-mesa-glx swig\n",
        "!pip install git+https://github.com/AI4Finance-Foundation/FinRL.git\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ZmuaPTCTFLr",
      "metadata": {
        "id": "9ZmuaPTCTFLr"
      },
      "source": [
        "Install other libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "f5kxWG9krFQS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "f5kxWG9krFQS",
        "outputId": "cad78abe-3cce-4210-9a16-4f94dbcc7bef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting akshare\n",
            "  Downloading akshare-1.16.77-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: aiohttp>=3.11.13 in /usr/local/lib/python3.11/site-packages (from akshare) (3.11.16)\n",
            "Requirement already satisfied: beautifulsoup4>=4.9.1 in /usr/local/lib/python3.11/site-packages (from akshare) (4.13.3)\n",
            "Requirement already satisfied: lxml>=4.2.1 in /usr/local/lib/python3.11/site-packages (from akshare) (5.3.2)\n",
            "Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.11/site-packages (from akshare) (2.2.3)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.11/site-packages (from akshare) (2.32.3)\n",
            "Collecting html5lib>=1.0.1 (from akshare)\n",
            "  Downloading html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Collecting xlrd>=1.2.0 (from akshare)\n",
            "  Downloading xlrd-2.0.1-py2.py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: urllib3>=1.25.8 in /usr/local/lib/python3.11/site-packages (from akshare) (1.26.20)\n",
            "Requirement already satisfied: tqdm>=4.43.0 in /usr/local/lib/python3.11/site-packages (from akshare) (4.67.1)\n",
            "Collecting openpyxl>=3.0.3 (from akshare)\n",
            "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting jsonpath>=0.82 (from akshare)\n",
            "  Downloading jsonpath-0.82.2.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tabulate>=0.8.6 (from akshare)\n",
            "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
            "Requirement already satisfied: decorator>=4.4.2 in /usr/local/lib/python3.11/site-packages (from akshare) (5.2.1)\n",
            "Collecting nest_asyncio>=1.6.0 (from akshare)\n",
            "  Downloading nest_asyncio-1.6.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting py-mini-racer>=0.6.0 (from akshare)\n",
            "  Downloading py_mini_racer-0.6.0-py2.py3-none-manylinux1_x86_64.whl.metadata (8.7 kB)\n",
            "Collecting akracer>=0.0.13 (from akracer[py-mini-racer]>=0.0.13; platform_system == \"Linux\"->akshare)\n",
            "  Downloading akracer-0.0.13-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/site-packages (from aiohttp>=3.11.13->akshare) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/site-packages (from aiohttp>=3.11.13->akshare) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/site-packages (from aiohttp>=3.11.13->akshare) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/site-packages (from aiohttp>=3.11.13->akshare) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/site-packages (from aiohttp>=3.11.13->akshare) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/site-packages (from aiohttp>=3.11.13->akshare) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/site-packages (from aiohttp>=3.11.13->akshare) (1.19.0)\n",
            "\u001b[33mWARNING: akracer 0.0.13 does not provide the extra 'py-mini-racer'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/site-packages (from beautifulsoup4>=4.9.1->akshare) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/site-packages (from beautifulsoup4>=4.9.1->akshare) (4.13.2)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.11/site-packages (from html5lib>=1.0.1->akshare) (1.17.0)\n",
            "Collecting webencodings (from html5lib>=1.0.1->akshare)\n",
            "  Downloading webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting et-xmlfile (from openpyxl>=3.0.3->akshare)\n",
            "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/site-packages (from pandas>=0.25->akshare) (2.2.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/site-packages (from pandas>=0.25->akshare) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/site-packages (from pandas>=0.25->akshare) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/site-packages (from pandas>=0.25->akshare) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests>=2.22.0->akshare) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests>=2.22.0->akshare) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests>=2.22.0->akshare) (2024.12.14)\n",
            "Downloading akshare-1.16.77-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading akracer-0.0.13-py3-none-any.whl (10.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
            "Downloading nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\n",
            "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
            "Downloading py_mini_racer-0.6.0-py2.py3-none-manylinux1_x86_64.whl (5.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
            "Downloading xlrd-2.0.1-py2.py3-none-any.whl (96 kB)\n",
            "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
            "Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
            "Building wheels for collected packages: jsonpath\n",
            "  Building wheel for jsonpath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonpath: filename=jsonpath-0.82.2-py3-none-any.whl size=5668 sha256=7338b7e47f16b8878bf1050963428e2642c70577490cd98dc16067429b0fc9c4\n",
            "  Stored in directory: /root/.cache/pip/wheels/7d/b8/16/48bbd715040679311fa68cb564ad24a97d9a67fea5d4c848c8\n",
            "Successfully built jsonpath\n",
            "Installing collected packages: webencodings, py-mini-racer, jsonpath, xlrd, tabulate, nest_asyncio, html5lib, et-xmlfile, akracer, openpyxl, akshare\n",
            "Successfully installed akracer-0.0.13 akshare-1.16.77 et-xmlfile-2.0.0 html5lib-1.1 jsonpath-0.82.2 nest_asyncio-1.6.0 openpyxl-3.1.5 py-mini-racer-0.6.0 tabulate-0.9.0 webencodings-0.5.1 xlrd-2.0.1\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "7538e4d276514f4fb45545ea18c69c87",
              "pip_warning": {
                "packages": [
                  "html5lib",
                  "tabulate",
                  "webencodings"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%pip install akshare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "q6T3o9yTTFLr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6T3o9yTTFLr",
        "outputId": "47846431-51f2-47a1-84e0-caca90f62799"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['HT_DCPERIOD', 'HT_DCPHASE', 'HT_PHASOR', 'HT_SINE', 'HT_TRENDMODE', 'ADD', 'DIV', 'MAX', 'MAXINDEX', 'MIN', 'MININDEX', 'MINMAX', 'MINMAXINDEX', 'MULT', 'SUB', 'SUM', 'ACOS', 'ASIN', 'ATAN', 'CEIL', 'COS', 'COSH', 'EXP', 'FLOOR', 'LN', 'LOG10', 'SIN', 'SINH', 'SQRT', 'TAN', 'TANH', 'ADX', 'ADXR', 'APO', 'AROON', 'AROONOSC', 'BOP', 'CCI', 'CMO', 'DX', 'MACD', 'MACDEXT', 'MACDFIX', 'MFI', 'MINUS_DI', 'MINUS_DM', 'MOM', 'PLUS_DI', 'PLUS_DM', 'PPO', 'ROC', 'ROCP', 'ROCR', 'ROCR100', 'RSI', 'STOCH', 'STOCHF', 'STOCHRSI', 'TRIX', 'ULTOSC', 'WILLR', 'BBANDS', 'DEMA', 'EMA', 'HT_TRENDLINE', 'KAMA', 'MA', 'MAMA', 'MAVP', 'MIDPOINT', 'MIDPRICE', 'SAR', 'SAREXT', 'SMA', 'T3', 'TEMA', 'TRIMA', 'WMA', 'CDL2CROWS', 'CDL3BLACKCROWS', 'CDL3INSIDE', 'CDL3LINESTRIKE', 'CDL3OUTSIDE', 'CDL3STARSINSOUTH', 'CDL3WHITESOLDIERS', 'CDLABANDONEDBABY', 'CDLADVANCEBLOCK', 'CDLBELTHOLD', 'CDLBREAKAWAY', 'CDLCLOSINGMARUBOZU', 'CDLCONCEALBABYSWALL', 'CDLCOUNTERATTACK', 'CDLDARKCLOUDCOVER', 'CDLDOJI', 'CDLDOJISTAR', 'CDLDRAGONFLYDOJI', 'CDLENGULFING', 'CDLEVENINGDOJISTAR', 'CDLEVENINGSTAR', 'CDLGAPSIDESIDEWHITE', 'CDLGRAVESTONEDOJI', 'CDLHAMMER', 'CDLHANGINGMAN', 'CDLHARAMI', 'CDLHARAMICROSS', 'CDLHIGHWAVE', 'CDLHIKKAKE', 'CDLHIKKAKEMOD', 'CDLHOMINGPIGEON', 'CDLIDENTICAL3CROWS', 'CDLINNECK', 'CDLINVERTEDHAMMER', 'CDLKICKING', 'CDLKICKINGBYLENGTH', 'CDLLADDERBOTTOM', 'CDLLONGLEGGEDDOJI', 'CDLLONGLINE', 'CDLMARUBOZU', 'CDLMATCHINGLOW', 'CDLMATHOLD', 'CDLMORNINGDOJISTAR', 'CDLMORNINGSTAR', 'CDLONNECK', 'CDLPIERCING', 'CDLRICKSHAWMAN', 'CDLRISEFALL3METHODS', 'CDLSEPARATINGLINES', 'CDLSHOOTINGSTAR', 'CDLSHORTLINE', 'CDLSPINNINGTOP', 'CDLSTALLEDPATTERN', 'CDLSTICKSANDWICH', 'CDLTAKURI', 'CDLTASUKIGAP', 'CDLTHRUSTING', 'CDLTRISTAR', 'CDLUNIQUE3RIVER', 'CDLUPSIDEGAP2CROWS', 'CDLXSIDEGAP3METHODS', 'AVGPRICE', 'MEDPRICE', 'TYPPRICE', 'WCLPRICE', 'BETA', 'CORREL', 'LINEARREG', 'LINEARREG_ANGLE', 'LINEARREG_INTERCEPT', 'LINEARREG_SLOPE', 'STDDEV', 'TSF', 'VAR', 'ATR', 'NATR', 'TRANGE', 'AD', 'ADOSC', 'OBV']\n"
          ]
        }
      ],
      "source": [
        "!pip install stockstats\n",
        "!pip install tushare\n",
        "#install talib\n",
        "!rm -f /usr/lib/libta*\n",
        "!wget https://github.com/ta-lib/ta-lib/releases/download/v0.6.4/ta-lib-0.6.4-src.tar.gz\n",
        "!tar xvzf ta-lib-0.6.4-src.tar.gz\n",
        "import os\n",
        "os.chdir('ta-lib-0.6.4')\n",
        "!./configure --prefix=/usr\n",
        "!make\n",
        "!make install\n",
        "!ln -s /usr/lib/libta-lib.so.0.0.0 /usr/lib/libta_lib.so.0\n",
        "#!sudo make install # Sometimes it need root\n",
        "os.chdir('../')\n",
        "!pip uninstall -y TA-Lib\n",
        "!pip install --no-binary :all: TA-Lib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "Q4aKqo9f_Nln",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4aKqo9f_Nln",
        "outputId": "1d5a0107-42ca-4678-d4fd-f27f7e53acbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 4397614 Apr 15 10:13 /usr/lib/libta-lib.a\n",
            "-rwxr-xr-x 1 root root     946 Apr 15 10:13 /usr/lib/libta-lib.la\n",
            "lrwxrwxrwx 1 root root      18 Apr 15 10:13 /usr/lib/libta-lib.so -> libta-lib.so.0.0.0\n",
            "lrwxrwxrwx 1 root root      18 Apr 15 10:13 /usr/lib/libta-lib.so.0 -> libta-lib.so.0.0.0\n",
            "-rwxr-xr-x 1 root root 2381472 Apr 15 10:13 /usr/lib/libta-lib.so.0.0.0\n"
          ]
        }
      ],
      "source": [
        "!ls -l /usr/lib/libta*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "DrReji1OTFLr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrReji1OTFLr",
        "outputId": "4e000f81-a7f4-4b57-89a3-7ce8b1221b14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/\n",
            "fatal: destination path 'FinRL-Meta' already exists and is not an empty directory.\n",
            "/FinRL-Meta\n"
          ]
        }
      ],
      "source": [
        "%cd /\n",
        "!git clone https://github.com/AI4Finance-Foundation/FinRL-Meta\n",
        "%cd /FinRL-Meta/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "C-MYxgpJTMGP",
      "metadata": {
        "id": "C-MYxgpJTMGP"
      },
      "source": [
        "## Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "Vx_hcZwgTKQp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vx_hcZwgTKQp",
        "outputId": "27a1bf46-5a66-47aa-84bd-c1e8b3e68faa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/shuzhenyi/code/FinRL-Meta\n",
            "ALL Modules have been imported!\n"
          ]
        }
      ],
      "source": [
        "%cd /home/shuzhenyi/code/FinRL-Meta\n",
        "\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import pandas as pd\n",
        "from IPython import display\n",
        "\n",
        "display.set_matplotlib_formats(\"svg\")\n",
        "\n",
        "from meta import config\n",
        "from meta.data_processor import DataProcessor\n",
        "from main import check_and_make_directories\n",
        "from meta.data_processors.tushare import Tushare, ReturnPlotter\n",
        "from meta.env_stock_trading.env_stocktrading_China_A_shares import StockTradingEnv\n",
        "from agents.stablebaselines3_models import DRLAgent\n",
        "import os\n",
        "from typing import List\n",
        "from argparse import ArgumentParser\n",
        "from meta import config\n",
        "from meta.config_tickers import DOW_30_TICKER\n",
        "from meta.config import ( DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR, INDICATORS, TRAIN_START_DATE, TRAIN_END_DATE, TEST_START_DATE, TEST_END_DATE, TRADE_START_DATE, TRADE_END_DATE, ERL_PARAMS, RLlib_PARAMS, SAC_PARAMS, ALPACA_API_KEY, ALPACA_API_SECRET, ALPACA_API_BASE_URL, )\n",
        "from meta.data_processors._base import DataSource\n",
        "\n",
        "import pyfolio\n",
        "from pyfolio import timeseries\n",
        "\n",
        "pd.options.display.max_columns = None\n",
        "\n",
        "print(\"ALL Modules have been imported!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FRQz2ptSTjPJ",
      "metadata": {
        "id": "FRQz2ptSTjPJ"
      },
      "source": [
        "## Create Folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "pmttRZWWTXcd",
      "metadata": {
        "id": "pmttRZWWTXcd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "'''\n",
        "use check_and_make_directories() to replace the following\n",
        "\n",
        "if not os.path.exists(\"./datasets\"):\n",
        "  os.makedirs(\"./datasets\")\n",
        "if not os.path.exists(\"./trained_models\"):\n",
        "  os.makedirs(\"./trained_models\")\n",
        "if not os.path.exists(\"./tensorboard_log\"):\n",
        "  os.makedirs(\"./tensorboard_log\")\n",
        "if not os.path.exists(\"./results\"):\n",
        "  os.makedirs(\"./results\")\n",
        "'''\n",
        "\n",
        "check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94s2JtmxTuLq",
      "metadata": {
        "id": "94s2JtmxTuLq"
      },
      "source": [
        "## Download data, cleaning and feature engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xpPTz-xDTovy",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpPTz-xDTovy",
        "outputId": "f9c8b3e2-2a58-43e3-b3f1-3b40d9a3306e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataSource.tushare successfully connected\n"
          ]
        }
      ],
      "source": [
        "ticker_list = ['600000.SH', '600009.SH', '600016.SH', '600028.SH', '600030.SH', '600031.SH', '600036.SH', '600050.SH', '600104.SH', '600196.SH', '600276.SH', '600309.SH', '600519.SH', '600547.SH', '600570.SH']\n",
        "\n",
        "TRAIN_START_DATE = '2015-01-01'\n",
        "TRAIN_END_DATE= '2019-08-01'\n",
        "TRADE_START_DATE = '2019-08-01'\n",
        "TRADE_END_DATE = '2020-01-03'\n",
        "\n",
        "TIME_INTERVAL = \"1d\"\n",
        "kwargs = {}\n",
        "kwargs['token'] = '2739bd3af641326a97a330c4f0890b5a7c7992b252e310be176d310e'\n",
        "p = DataProcessor(data_source=DataSource.tushare, start_date=TRAIN_START_DATE, end_date=TRADE_END_DATE, time_interval=TIME_INTERVAL, **kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "svZh2OT0T7PG",
      "metadata": {
        "id": "svZh2OT0T7PG"
      },
      "source": [
        "### Download and Clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "v_PzruLIT3D1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_PzruLIT3D1",
        "outputId": "7b5ff0ac-2550-4f97-a1f4-df97947488f8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:17<00:00,  1.18s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Download complete! Dataset saved to ./data/dataset.csv. \n",
            "Shape of DataFrame: (17960, 8)\n",
            "Shape of DataFrame:  (18315, 8)\n"
          ]
        }
      ],
      "source": [
        "p.download_data(ticker_list=ticker_list)\n",
        "p.clean_data()\n",
        "p.fillna()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tsHu-XT_T_vQ",
      "metadata": {
        "id": "tsHu-XT_T_vQ"
      },
      "source": [
        "### Add technical indicator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VfniyyQQT3nq",
      "metadata": {
        "id": "VfniyyQQT3nq",
        "outputId": "10a08e6a-a9a6-41b1-913e-51f75a3e4ed9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tech_indicator_list:  ['macd', 'boll_ub', 'boll_lb', 'rsi_30', 'cci_30', 'dx_30', 'close_30_sma', 'close_60_sma']\n",
            "indicator:  macd\n",
            "indicator:  boll_ub\n",
            "indicator:  boll_lb\n",
            "indicator:  rsi_30\n",
            "indicator:  cci_30\n",
            "indicator:  dx_30\n",
            "indicator:  close_30_sma\n",
            "indicator:  close_60_sma\n",
            "Succesfully add technical indicators\n",
            "Shape of DataFrame:  (18270, 17)\n"
          ]
        }
      ],
      "source": [
        "p.add_technical_indicator(config.INDICATORS)\n",
        "p.fillna()\n",
        "\n",
        "#print(f\"p.dataframe: {p.dataframe}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cKZk3jGuUR34",
      "metadata": {
        "id": "cKZk3jGuUR34"
      },
      "source": [
        "## Split training dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "SuKbrwflUVeU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuKbrwflUVeU",
        "outputId": "4cba2994-3eab-4d79-8fd6-029eb4e4b3d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "len(train.tic.unique()): 15\n"
          ]
        }
      ],
      "source": [
        "train = p.data_split(p.dataframe, TRAIN_START_DATE, TRAIN_END_DATE)\n",
        "\n",
        "print(f\"len(train.tic.unique()): {len(train.tic.unique())}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "5ONAnSMBUWyu",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ONAnSMBUWyu",
        "outputId": "d40acf05-9a4d-4e0c-a2cc-440036718a6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train.tic.unique(): ['600000.SH' '600009.SH' '600016.SH' '600028.SH' '600030.SH' '600031.SH'\n",
            " '600036.SH' '600050.SH' '600104.SH' '600196.SH' '600276.SH' '600309.SH'\n",
            " '600519.SH' '600547.SH' '600570.SH']\n"
          ]
        }
      ],
      "source": [
        "print(f\"train.tic.unique(): {train.tic.unique()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "BXF8hYDvUXfv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXF8hYDvUXfv",
        "outputId": "ec92e31d-4c69-4480-d41f-4dcab1484cf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train.head():          tic        time   open   high    low  close  adjusted_close  \\\n",
            "0  600000.SH  2015-01-05  15.88  16.25  15.56  16.07           16.07   \n",
            "0  600009.SH  2015-01-05  19.82  20.91  19.82  20.53           20.53   \n",
            "0  600016.SH  2015-01-05  10.87  10.96  10.50  10.78           10.78   \n",
            "0  600028.SH  2015-01-05   6.59   7.14   6.45   7.14            7.14   \n",
            "0  600030.SH  2015-01-05  33.90  35.25  33.01  34.66           34.66   \n",
            "\n",
            "        volume  \n",
            "0   5135687.09  \n",
            "0    371485.54  \n",
            "0   9138873.70  \n",
            "0  11864996.45  \n",
            "0   6986272.15  \n"
          ]
        }
      ],
      "source": [
        "print(f\"train.head(): {train.head()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "CnwNoBG5UXSQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnwNoBG5UXSQ",
        "outputId": "9ef997fc-6edf-47b8-9799-a6430548ddb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train.shape: (16740, 8)\n"
          ]
        }
      ],
      "source": [
        "print(f\"train.shape: {train.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "joNhXi_ZUXId",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joNhXi_ZUXId",
        "outputId": "30adf199-8894-4a9c-be11-a3de7f101fc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stock Dimension: 15, State Space: 151\n"
          ]
        }
      ],
      "source": [
        "stock_dimension = len(train.tic.unique())\n",
        "state_space = stock_dimension * (len(config.INDICATORS) + 2) + 1\n",
        "\n",
        "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "le09273cUmzH",
      "metadata": {
        "id": "le09273cUmzH"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "Npwpqkr7UpFF",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Npwpqkr7UpFF",
        "outputId": "3beebc50-fc36-4704-f2c1-89f843f96b6d"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'macd'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'macd'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-849f09509c43>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0menv_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m \u001b[0;34m\"stock_dim\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstock_dimension\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"hmax\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"initial_amount\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1000000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"buy_cost_pct\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m6.87e-5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sell_cost_pct\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.0687e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"reward_scaling\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"state_space\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstate_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"action_space\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstock_dimension\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tech_indicator_list\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINDICATORS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"print_verbosity\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"initial_buy\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"hundred_each_trade\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0me_train_gym\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStockTradingEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0menv_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/FinRL-Meta/meta/env_stock_trading/env_stocktrading_China_A_shares.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, df, stock_dim, hmax, initial_amount, buy_cost_pct, sell_cost_pct, reward_scaling, state_space, action_space, tech_indicator_list, turbulence_threshold, make_plots, print_verbosity, day, initial, previous_state, model_name, mode, iteration, initial_buy, hundred_each_trade)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_buy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_buy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhundred_each_trade\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhundred_each_trade\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initiate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# initialize reward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/FinRL-Meta/meta/env_stock_trading/env_stocktrading_China_A_shares.py\u001b[0m in \u001b[0;36m_initiate_state\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    345\u001b[0m                     \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstock_dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m                     + sum(\n\u001b[0;32m--> 347\u001b[0;31m                         [\n\u001b[0m\u001b[1;32m    348\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtech\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m                             \u001b[0;32mfor\u001b[0m \u001b[0mtech\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtech_indicator_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/FinRL-Meta/meta/env_stock_trading/env_stocktrading_China_A_shares.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    346\u001b[0m                     + sum(\n\u001b[1;32m    347\u001b[0m                         [\n\u001b[0;32m--> 348\u001b[0;31m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtech\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m                             \u001b[0;32mfor\u001b[0m \u001b[0mtech\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtech_indicator_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m                         ],\n",
            "\u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'macd'"
          ]
        }
      ],
      "source": [
        "env_kwargs = { \"stock_dim\": stock_dimension, \"hmax\": 1000, \"initial_amount\": 1000000, \"buy_cost_pct\": 6.87e-5, \"sell_cost_pct\": 1.0687e-3, \"reward_scaling\": 1e-4, \"state_space\": state_space, \"action_space\": stock_dimension, \"tech_indicator_list\": config.INDICATORS, \"print_verbosity\": 1, \"initial_buy\": True, \"hundred_each_trade\": True }\n",
        "\n",
        "e_train_gym = StockTradingEnv(df=train, **env_kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1POZL3nUyDY",
      "metadata": {
        "id": "f1POZL3nUyDY"
      },
      "outputs": [],
      "source": [
        "env_train, _ = e_train_gym.get_sb_env()\n",
        "\n",
        "print(f\"print(type(env_train)): {print(type(env_train))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QkY8sVWhU6PH",
      "metadata": {
        "id": "QkY8sVWhU6PH"
      },
      "source": [
        "### DDPG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dLjEviBhUzuc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLjEviBhUzuc",
        "outputId": "58226aaa-41dc-45ce-9f5c-1e5cb94d27a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'batch_size': 256, 'buffer_size': 50000, 'learning_rate': 0.0005, 'action_noise': NormalActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1])}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ddpg/ddpg_1\n",
            "Episode: 2\n",
            "day: 1112, episode: 2\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 2109049.67\n",
            "total_reward: 1109049.67\n",
            "total_cost: 12151.48\n",
            "total_trades: 16679\n",
            "Sharpe: 0.726\n",
            "=================================\n",
            "Episode: 3\n",
            "day: 1112, episode: 3\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1873632.31\n",
            "total_reward: 873632.31\n",
            "total_cost: 620.69\n",
            "total_trades: 16680\n",
            "Sharpe: 0.650\n",
            "=================================\n",
            "Episode: 4\n",
            "day: 1112, episode: 4\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1480411.95\n",
            "total_reward: 480411.95\n",
            "total_cost: 488.05\n",
            "total_trades: 16680\n",
            "Sharpe: 0.471\n",
            "=================================\n",
            "Episode: 5\n",
            "day: 1112, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1473792.94\n",
            "total_reward: 473792.94\n",
            "total_cost: 488.06\n",
            "total_trades: 16680\n",
            "Sharpe: 0.467\n",
            "=================================\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 4          |\n",
            "|    fps             | 26         |\n",
            "|    time_elapsed    | 170        |\n",
            "|    total_timesteps | 4452       |\n",
            "| train/             |            |\n",
            "|    actor_loss      | -670       |\n",
            "|    critic_loss     | 1.54e+03   |\n",
            "|    learning_rate   | 0.0005     |\n",
            "|    n_updates       | 3339       |\n",
            "|    reward          | -1.7532761 |\n",
            "-----------------------------------\n",
            "Episode: 6\n",
            "day: 1112, episode: 6\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1459229.94\n",
            "total_reward: 459229.94\n",
            "total_cost: 488.06\n",
            "total_trades: 16680\n",
            "Sharpe: 0.456\n",
            "=================================\n",
            "Episode: 7\n",
            "day: 1112, episode: 7\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1479962.94\n",
            "total_reward: 479962.94\n",
            "total_cost: 488.06\n",
            "total_trades: 16680\n",
            "Sharpe: 0.471\n",
            "=================================\n",
            "Episode: 8\n",
            "day: 1112, episode: 8\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1485250.97\n",
            "total_reward: 485250.97\n",
            "total_cost: 488.03\n",
            "total_trades: 16680\n",
            "Sharpe: 0.474\n",
            "=================================\n",
            "Episode: 9\n",
            "day: 1112, episode: 9\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1493105.94\n",
            "total_reward: 493105.94\n",
            "total_cost: 488.06\n",
            "total_trades: 16680\n",
            "Sharpe: 0.480\n",
            "=================================\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 8          |\n",
            "|    fps             | 24         |\n",
            "|    time_elapsed    | 369        |\n",
            "|    total_timesteps | 8904       |\n",
            "| train/             |            |\n",
            "|    actor_loss      | -806       |\n",
            "|    critic_loss     | 323        |\n",
            "|    learning_rate   | 0.0005     |\n",
            "|    n_updates       | 7791       |\n",
            "|    reward          | -1.8583821 |\n",
            "-----------------------------------\n",
            "Episode: 10\n",
            "day: 1112, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1474497.96\n",
            "total_reward: 474497.96\n",
            "total_cost: 488.04\n",
            "total_trades: 16680\n",
            "Sharpe: 0.466\n",
            "=================================\n"
          ]
        }
      ],
      "source": [
        "agent = DRLAgent(env=env_train)\n",
        "DDPG_PARAMS = { \"batch_size\": 256, \"buffer_size\": 50000, \"learning_rate\": 0.0005, \"action_noise\": \"normal\", }\n",
        "POLICY_KWARGS = dict(net_arch=dict(pi=[64, 64], qf=[400, 300]))\n",
        "model_ddpg = agent.get_model(\"ddpg\", model_kwargs=DDPG_PARAMS, policy_kwargs=POLICY_KWARGS)\n",
        "\n",
        "trained_ddpg = agent.train_model(model=model_ddpg, tb_log_name='ddpg', total_timesteps=10000)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ALJ1gqVmVEiU",
      "metadata": {
        "id": "ALJ1gqVmVEiU"
      },
      "source": [
        "### A2C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2F5qCGnNUzm7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2F5qCGnNUzm7",
        "outputId": "b8db239f-7d37-4587-c511-0f2dc4c6f273"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/a2c/a2c_1\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 251        |\n",
            "|    iterations         | 100        |\n",
            "|    time_elapsed       | 1          |\n",
            "|    total_timesteps    | 500        |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -21.3      |\n",
            "|    explained_variance | -0.0322    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 99         |\n",
            "|    policy_loss        | -2.66      |\n",
            "|    reward             | -0.5146969 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 2.24       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 248       |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 4         |\n",
            "|    total_timesteps    | 1000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -21.3     |\n",
            "|    explained_variance | -0.021    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 199       |\n",
            "|    policy_loss        | 25.7      |\n",
            "|    reward             | 3.5938816 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 2.07      |\n",
            "-------------------------------------\n",
            "Episode: 12\n",
            "day: 1112, episode: 12\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1020213.39\n",
            "total_reward: 20213.39\n",
            "total_cost: 56550.76\n",
            "total_trades: 16666\n",
            "Sharpe: 0.161\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 249       |\n",
            "|    iterations         | 300       |\n",
            "|    time_elapsed       | 6         |\n",
            "|    total_timesteps    | 1500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -21.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 299       |\n",
            "|    policy_loss        | -12.4     |\n",
            "|    reward             | 0.6872746 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 2.18      |\n",
            "-------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 249          |\n",
            "|    iterations         | 400          |\n",
            "|    time_elapsed       | 8            |\n",
            "|    total_timesteps    | 2000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -21.3        |\n",
            "|    explained_variance | -0.00236     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 399          |\n",
            "|    policy_loss        | -73.6        |\n",
            "|    reward             | -0.016160956 |\n",
            "|    std                | 1            |\n",
            "|    value_loss         | 16           |\n",
            "----------------------------------------\n",
            "Episode: 13\n",
            "day: 1112, episode: 13\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1135176.66\n",
            "total_reward: 135176.66\n",
            "total_cost: 73436.34\n",
            "total_trades: 16660\n",
            "Sharpe: 0.290\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 247        |\n",
            "|    iterations         | 500        |\n",
            "|    time_elapsed       | 10         |\n",
            "|    total_timesteps    | 2500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -21.4      |\n",
            "|    explained_variance | -0.538     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 499        |\n",
            "|    policy_loss        | 23.1       |\n",
            "|    reward             | -5.0200696 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 2.38       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 244       |\n",
            "|    iterations         | 600       |\n",
            "|    time_elapsed       | 12        |\n",
            "|    total_timesteps    | 3000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -21.4     |\n",
            "|    explained_variance | 0.256     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 599       |\n",
            "|    policy_loss        | 91.8      |\n",
            "|    reward             | 1.2820133 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 23.9      |\n",
            "-------------------------------------\n",
            "Episode: 14\n",
            "day: 1112, episode: 14\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1452599.94\n",
            "total_reward: 452599.94\n",
            "total_cost: 72781.06\n",
            "total_trades: 16668\n",
            "Sharpe: 0.420\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 244         |\n",
            "|    iterations         | 700         |\n",
            "|    time_elapsed       | 14          |\n",
            "|    total_timesteps    | 3500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -21.4       |\n",
            "|    explained_variance | -0.0446     |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 699         |\n",
            "|    policy_loss        | -398        |\n",
            "|    reward             | -0.98048055 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 424         |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 242        |\n",
            "|    iterations         | 800        |\n",
            "|    time_elapsed       | 16         |\n",
            "|    total_timesteps    | 4000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -21.5      |\n",
            "|    explained_variance | -0.922     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 799        |\n",
            "|    policy_loss        | -17.4      |\n",
            "|    reward             | 0.28415835 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 0.873      |\n",
            "--------------------------------------\n",
            "Episode: 15\n",
            "day: 1112, episode: 15\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1721987.58\n",
            "total_reward: 721987.58\n",
            "total_cost: 101478.42\n",
            "total_trades: 16673\n",
            "Sharpe: 0.503\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 241       |\n",
            "|    iterations         | 900       |\n",
            "|    time_elapsed       | 18        |\n",
            "|    total_timesteps    | 4500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -21.5     |\n",
            "|    explained_variance | 0.159     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 899       |\n",
            "|    policy_loss        | 161       |\n",
            "|    reward             | 1.2920502 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 69.6      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 241         |\n",
            "|    iterations         | 1000        |\n",
            "|    time_elapsed       | 20          |\n",
            "|    total_timesteps    | 5000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -21.5       |\n",
            "|    explained_variance | -1.2        |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 999         |\n",
            "|    policy_loss        | 3.34        |\n",
            "|    reward             | -0.53188443 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 0.634       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 242        |\n",
            "|    iterations         | 1100       |\n",
            "|    time_elapsed       | 22         |\n",
            "|    total_timesteps    | 5500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -21.5      |\n",
            "|    explained_variance | 0.135      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1099       |\n",
            "|    policy_loss        | -38.6      |\n",
            "|    reward             | -1.1616651 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 5.67       |\n",
            "--------------------------------------\n",
            "Episode: 16\n",
            "day: 1112, episode: 16\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1785713.64\n",
            "total_reward: 785713.64\n",
            "total_cost: 91212.36\n",
            "total_trades: 16673\n",
            "Sharpe: 0.561\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 242         |\n",
            "|    iterations         | 1200        |\n",
            "|    time_elapsed       | 24          |\n",
            "|    total_timesteps    | 6000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -21.5       |\n",
            "|    explained_variance | -1.44       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1199        |\n",
            "|    policy_loss        | -49.5       |\n",
            "|    reward             | -0.16244832 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 5.77        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 242         |\n",
            "|    iterations         | 1300        |\n",
            "|    time_elapsed       | 26          |\n",
            "|    total_timesteps    | 6500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -21.6       |\n",
            "|    explained_variance | -0.218      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1299        |\n",
            "|    policy_loss        | -2.18       |\n",
            "|    reward             | -0.65589225 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 5.23        |\n",
            "---------------------------------------\n",
            "Episode: 17\n",
            "day: 1112, episode: 17\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 656554.83\n",
            "total_reward: -343445.17\n",
            "total_cost: 94231.17\n",
            "total_trades: 16670\n",
            "Sharpe: -0.008\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 242        |\n",
            "|    iterations         | 1400       |\n",
            "|    time_elapsed       | 28         |\n",
            "|    total_timesteps    | 7000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -21.6      |\n",
            "|    explained_variance | -0.0815    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1399       |\n",
            "|    policy_loss        | -27.4      |\n",
            "|    reward             | 0.47324356 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 5.58       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 242        |\n",
            "|    iterations         | 1500       |\n",
            "|    time_elapsed       | 30         |\n",
            "|    total_timesteps    | 7500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -21.5      |\n",
            "|    explained_variance | -0.29      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1499       |\n",
            "|    policy_loss        | -25.6      |\n",
            "|    reward             | 0.07530492 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 2.54       |\n",
            "--------------------------------------\n",
            "Episode: 18\n",
            "day: 1112, episode: 18\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 756839.88\n",
            "total_reward: -243160.12\n",
            "total_cost: 77117.12\n",
            "total_trades: 16667\n",
            "Sharpe: -0.039\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 242         |\n",
            "|    iterations         | 1600        |\n",
            "|    time_elapsed       | 33          |\n",
            "|    total_timesteps    | 8000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -21.5       |\n",
            "|    explained_variance | -0.353      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1599        |\n",
            "|    policy_loss        | 13.3        |\n",
            "|    reward             | -0.86519796 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 2.27        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 242        |\n",
            "|    iterations         | 1700       |\n",
            "|    time_elapsed       | 35         |\n",
            "|    total_timesteps    | 8500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -21.6      |\n",
            "|    explained_variance | 0.0211     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1699       |\n",
            "|    policy_loss        | 42.4       |\n",
            "|    reward             | 0.19230042 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 6.29       |\n",
            "--------------------------------------\n",
            "Episode: 19\n",
            "day: 1112, episode: 19\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 677799.00\n",
            "total_reward: -322201.00\n",
            "total_cost: 26499.00\n",
            "total_trades: 16673\n",
            "Sharpe: -0.227\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 242      |\n",
            "|    iterations         | 1800     |\n",
            "|    time_elapsed       | 37       |\n",
            "|    total_timesteps    | 9000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -21.6    |\n",
            "|    explained_variance | -0.724   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1799     |\n",
            "|    policy_loss        | 63.7     |\n",
            "|    reward             | 3.120001 |\n",
            "|    std                | 1.02     |\n",
            "|    value_loss         | 23       |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 243       |\n",
            "|    iterations         | 1900      |\n",
            "|    time_elapsed       | 39        |\n",
            "|    total_timesteps    | 9500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -21.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1899      |\n",
            "|    policy_loss        | -42.6     |\n",
            "|    reward             | 2.0565643 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 3.17      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 243        |\n",
            "|    iterations         | 2000       |\n",
            "|    time_elapsed       | 41         |\n",
            "|    total_timesteps    | 10000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -21.6      |\n",
            "|    explained_variance | 0.0867     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1999       |\n",
            "|    policy_loss        | 48.8       |\n",
            "|    reward             | 0.42696014 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 7.17       |\n",
            "--------------------------------------\n",
            "Episode: 20\n",
            "day: 1112, episode: 20\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1162416.81\n",
            "total_reward: 162416.81\n",
            "total_cost: 61973.19\n",
            "total_trades: 16671\n",
            "Sharpe: 0.263\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 244        |\n",
            "|    iterations         | 2100       |\n",
            "|    time_elapsed       | 43         |\n",
            "|    total_timesteps    | 10500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -21.6      |\n",
            "|    explained_variance | -0.596     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2099       |\n",
            "|    policy_loss        | -3.97      |\n",
            "|    reward             | 0.03327369 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 0.487      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 244         |\n",
            "|    iterations         | 2200        |\n",
            "|    time_elapsed       | 45          |\n",
            "|    total_timesteps    | 11000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -21.6       |\n",
            "|    explained_variance | 0.055       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2199        |\n",
            "|    policy_loss        | 52.4        |\n",
            "|    reward             | -0.16659752 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 8.07        |\n",
            "---------------------------------------\n",
            "Episode: 21\n",
            "day: 1112, episode: 21\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1250840.39\n",
            "total_reward: 250840.39\n",
            "total_cost: 51180.61\n",
            "total_trades: 16673\n",
            "Sharpe: 0.320\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 243        |\n",
            "|    iterations         | 2300       |\n",
            "|    time_elapsed       | 47         |\n",
            "|    total_timesteps    | 11500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -21.6      |\n",
            "|    explained_variance | 0.0503     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2299       |\n",
            "|    policy_loss        | 22.3       |\n",
            "|    reward             | -0.5018876 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 1.37       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 243        |\n",
            "|    iterations         | 2400       |\n",
            "|    time_elapsed       | 49         |\n",
            "|    total_timesteps    | 12000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -21.6      |\n",
            "|    explained_variance | -0.175     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2399       |\n",
            "|    policy_loss        | 50.1       |\n",
            "|    reward             | -2.8187664 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 7.04       |\n",
            "--------------------------------------\n",
            "Episode: 22\n",
            "day: 1112, episode: 22\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1328636.65\n",
            "total_reward: 328636.65\n",
            "total_cost: 74018.35\n",
            "total_trades: 16673\n",
            "Sharpe: 0.373\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 242       |\n",
            "|    iterations         | 2500      |\n",
            "|    time_elapsed       | 51        |\n",
            "|    total_timesteps    | 12500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -21.7     |\n",
            "|    explained_variance | -0.57     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2499      |\n",
            "|    policy_loss        | 11.8      |\n",
            "|    reward             | -3.533615 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 1.71      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 241      |\n",
            "|    iterations         | 2600     |\n",
            "|    time_elapsed       | 53       |\n",
            "|    total_timesteps    | 13000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -21.6    |\n",
            "|    explained_variance | 0.019    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2599     |\n",
            "|    policy_loss        | 38.6     |\n",
            "|    reward             | -4.54127 |\n",
            "|    std                | 1.02     |\n",
            "|    value_loss         | 5.79     |\n",
            "------------------------------------\n",
            "Episode: 23\n",
            "day: 1112, episode: 23\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1481294.41\n",
            "total_reward: 481294.41\n",
            "total_cost: 84745.59\n",
            "total_trades: 16670\n",
            "Sharpe: 0.466\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 241       |\n",
            "|    iterations         | 2700      |\n",
            "|    time_elapsed       | 55        |\n",
            "|    total_timesteps    | 13500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -21.6     |\n",
            "|    explained_variance | -0.186    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2699      |\n",
            "|    policy_loss        | -4.68     |\n",
            "|    reward             | 4.4285936 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 3.12      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 241       |\n",
            "|    iterations         | 2800      |\n",
            "|    time_elapsed       | 58        |\n",
            "|    total_timesteps    | 14000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -21.7     |\n",
            "|    explained_variance | -0.805    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2799      |\n",
            "|    policy_loss        | 17.8      |\n",
            "|    reward             | 0.2522968 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 1.26      |\n",
            "-------------------------------------\n",
            "Episode: 24\n",
            "day: 1112, episode: 24\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1055641.36\n",
            "total_reward: 55641.36\n",
            "total_cost: 71306.64\n",
            "total_trades: 16671\n",
            "Sharpe: 0.175\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 241         |\n",
            "|    iterations         | 2900        |\n",
            "|    time_elapsed       | 60          |\n",
            "|    total_timesteps    | 14500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -21.7       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2899        |\n",
            "|    policy_loss        | 5.2         |\n",
            "|    reward             | -0.13718218 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 0.268       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 241         |\n",
            "|    iterations         | 3000        |\n",
            "|    time_elapsed       | 62          |\n",
            "|    total_timesteps    | 15000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -21.7       |\n",
            "|    explained_variance | -0.0745     |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2999        |\n",
            "|    policy_loss        | 5.71        |\n",
            "|    reward             | -0.21766275 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 0.702       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 241       |\n",
            "|    iterations         | 3100      |\n",
            "|    time_elapsed       | 64        |\n",
            "|    total_timesteps    | 15500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -21.6     |\n",
            "|    explained_variance | -0.148    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3099      |\n",
            "|    policy_loss        | -109      |\n",
            "|    reward             | 1.8754544 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 37.1      |\n",
            "-------------------------------------\n",
            "Episode: 25\n",
            "day: 1112, episode: 25\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1788462.53\n",
            "total_reward: 788462.53\n",
            "total_cost: 61901.47\n",
            "total_trades: 16670\n",
            "Sharpe: 0.602\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 241        |\n",
            "|    iterations         | 3200       |\n",
            "|    time_elapsed       | 66         |\n",
            "|    total_timesteps    | 16000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -21.6      |\n",
            "|    explained_variance | 0.0183     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3199       |\n",
            "|    policy_loss        | -71.5      |\n",
            "|    reward             | 0.35727146 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 12.4       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 241       |\n",
            "|    iterations         | 3300      |\n",
            "|    time_elapsed       | 68        |\n",
            "|    total_timesteps    | 16500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -21.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3299      |\n",
            "|    policy_loss        | -61.9     |\n",
            "|    reward             | -0.178148 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 10.3      |\n",
            "-------------------------------------\n",
            "Episode: 26\n",
            "day: 1112, episode: 26\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1101713.43\n",
            "total_reward: 101713.43\n",
            "total_cost: 69265.57\n",
            "total_trades: 16670\n",
            "Sharpe: 0.269\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 241         |\n",
            "|    iterations         | 3400        |\n",
            "|    time_elapsed       | 70          |\n",
            "|    total_timesteps    | 17000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -21.7       |\n",
            "|    explained_variance | -0.0763     |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3399        |\n",
            "|    policy_loss        | 24.7        |\n",
            "|    reward             | -0.15418828 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 2.64        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 241         |\n",
            "|    iterations         | 3500        |\n",
            "|    time_elapsed       | 72          |\n",
            "|    total_timesteps    | 17500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -21.7       |\n",
            "|    explained_variance | -0.245      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3499        |\n",
            "|    policy_loss        | -2.81       |\n",
            "|    reward             | -0.27856484 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 3.24        |\n",
            "---------------------------------------\n",
            "Episode: 27\n",
            "day: 1112, episode: 27\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 844132.69\n",
            "total_reward: -155867.31\n",
            "total_cost: 83509.31\n",
            "total_trades: 16670\n",
            "Sharpe: 0.101\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 241        |\n",
            "|    iterations         | 3600       |\n",
            "|    time_elapsed       | 74         |\n",
            "|    total_timesteps    | 18000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -21.7      |\n",
            "|    explained_variance | -0.00344   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3599       |\n",
            "|    policy_loss        | 164        |\n",
            "|    reward             | -1.6985158 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 84.3       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 241        |\n",
            "|    iterations         | 3700       |\n",
            "|    time_elapsed       | 76         |\n",
            "|    total_timesteps    | 18500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -21.7      |\n",
            "|    explained_variance | 0.0165     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3699       |\n",
            "|    policy_loss        | 56.2       |\n",
            "|    reward             | 0.91595215 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 6.95       |\n",
            "--------------------------------------\n",
            "Episode: 28\n",
            "day: 1112, episode: 28\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1386483.87\n",
            "total_reward: 386483.87\n",
            "total_cost: 95005.13\n",
            "total_trades: 16674\n",
            "Sharpe: 0.386\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 240        |\n",
            "|    iterations         | 3800       |\n",
            "|    time_elapsed       | 78         |\n",
            "|    total_timesteps    | 19000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -21.7      |\n",
            "|    explained_variance | -0.0153    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3799       |\n",
            "|    policy_loss        | -12        |\n",
            "|    reward             | 0.58676416 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 1.78       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 240        |\n",
            "|    iterations         | 3900       |\n",
            "|    time_elapsed       | 81         |\n",
            "|    total_timesteps    | 19500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -21.7      |\n",
            "|    explained_variance | 0.202      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3899       |\n",
            "|    policy_loss        | 17         |\n",
            "|    reward             | -2.4740417 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 1.34       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 240        |\n",
            "|    iterations         | 4000       |\n",
            "|    time_elapsed       | 83         |\n",
            "|    total_timesteps    | 20000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -21.7      |\n",
            "|    explained_variance | 0.0463     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3999       |\n",
            "|    policy_loss        | -129       |\n",
            "|    reward             | -1.3204368 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 43.6       |\n",
            "--------------------------------------\n",
            "Episode: 29\n",
            "day: 1112, episode: 29\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1586191.10\n",
            "total_reward: 586191.10\n",
            "total_cost: 80097.90\n",
            "total_trades: 16668\n",
            "Sharpe: 0.493\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 240       |\n",
            "|    iterations         | 4100      |\n",
            "|    time_elapsed       | 85        |\n",
            "|    total_timesteps    | 20500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -21.7     |\n",
            "|    explained_variance | -1.72     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4099      |\n",
            "|    policy_loss        | -22.7     |\n",
            "|    reward             | 1.4980443 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 1.58      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 240       |\n",
            "|    iterations         | 4200      |\n",
            "|    time_elapsed       | 87        |\n",
            "|    total_timesteps    | 21000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -21.7     |\n",
            "|    explained_variance | -0.532    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4199      |\n",
            "|    policy_loss        | -11.4     |\n",
            "|    reward             | -5.787773 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 3.18      |\n",
            "-------------------------------------\n",
            "Episode: 30\n",
            "day: 1112, episode: 30\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1777447.38\n",
            "total_reward: 777447.38\n",
            "total_cost: 90888.62\n",
            "total_trades: 16670\n",
            "Sharpe: 0.547\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 240          |\n",
            "|    iterations         | 4300         |\n",
            "|    time_elapsed       | 89           |\n",
            "|    total_timesteps    | 21500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -21.6        |\n",
            "|    explained_variance | 0.133        |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4299         |\n",
            "|    policy_loss        | -22.7        |\n",
            "|    reward             | -0.011666544 |\n",
            "|    std                | 1.02         |\n",
            "|    value_loss         | 1.85         |\n",
            "----------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 240       |\n",
            "|    iterations         | 4400      |\n",
            "|    time_elapsed       | 91        |\n",
            "|    total_timesteps    | 22000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -21.6     |\n",
            "|    explained_variance | -0.0931   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4399      |\n",
            "|    policy_loss        | -87.3     |\n",
            "|    reward             | 4.1830454 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 51        |\n",
            "-------------------------------------\n",
            "Episode: 31\n",
            "day: 1112, episode: 31\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1375149.07\n",
            "total_reward: 375149.07\n",
            "total_cost: 70406.93\n",
            "total_trades: 16670\n",
            "Sharpe: 0.385\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 240        |\n",
            "|    iterations         | 4500       |\n",
            "|    time_elapsed       | 93         |\n",
            "|    total_timesteps    | 22500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -21.6      |\n",
            "|    explained_variance | 0.0574     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4499       |\n",
            "|    policy_loss        | -11.7      |\n",
            "|    reward             | 0.38482484 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 1.46       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 240        |\n",
            "|    iterations         | 4600       |\n",
            "|    time_elapsed       | 95         |\n",
            "|    total_timesteps    | 23000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -21.6      |\n",
            "|    explained_variance | -0.0213    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4599       |\n",
            "|    policy_loss        | 126        |\n",
            "|    reward             | -3.5586853 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 42.1       |\n",
            "--------------------------------------\n",
            "Episode: 32\n",
            "day: 1112, episode: 32\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1483978.74\n",
            "total_reward: 483978.74\n",
            "total_cost: 78944.26\n",
            "total_trades: 16676\n",
            "Sharpe: 0.432\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 240       |\n",
            "|    iterations         | 4700      |\n",
            "|    time_elapsed       | 97        |\n",
            "|    total_timesteps    | 23500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -21.5     |\n",
            "|    explained_variance | 0.164     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4699      |\n",
            "|    policy_loss        | -13.4     |\n",
            "|    reward             | 2.8764431 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 7.06      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 241         |\n",
            "|    iterations         | 4800        |\n",
            "|    time_elapsed       | 99          |\n",
            "|    total_timesteps    | 24000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -21.5       |\n",
            "|    explained_variance | 0.392       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4799        |\n",
            "|    policy_loss        | 5.01        |\n",
            "|    reward             | -0.35039684 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 0.0779      |\n",
            "---------------------------------------\n",
            "Episode: 33\n",
            "day: 1112, episode: 33\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1060066.38\n",
            "total_reward: 60066.38\n",
            "total_cost: 45222.62\n",
            "total_trades: 16678\n",
            "Sharpe: 0.240\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 241        |\n",
            "|    iterations         | 4900       |\n",
            "|    time_elapsed       | 101        |\n",
            "|    total_timesteps    | 24500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -21.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4899       |\n",
            "|    policy_loss        | 12.5       |\n",
            "|    reward             | -0.8052268 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 0.379      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 241       |\n",
            "|    iterations         | 5000      |\n",
            "|    time_elapsed       | 103       |\n",
            "|    total_timesteps    | 25000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -21.6     |\n",
            "|    explained_variance | -0.0739   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4999      |\n",
            "|    policy_loss        | -18.7     |\n",
            "|    reward             | 1.3659521 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 1.24      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 241        |\n",
            "|    iterations         | 5100       |\n",
            "|    time_elapsed       | 105        |\n",
            "|    total_timesteps    | 25500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -21.6      |\n",
            "|    explained_variance | -0.239     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5099       |\n",
            "|    policy_loss        | 133        |\n",
            "|    reward             | -1.5272913 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 50.9       |\n",
            "--------------------------------------\n",
            "Episode: 34\n",
            "day: 1112, episode: 34\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1378748.53\n",
            "total_reward: 378748.53\n",
            "total_cost: 42573.47\n",
            "total_trades: 16679\n",
            "Sharpe: 0.388\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 241        |\n",
            "|    iterations         | 5200       |\n",
            "|    time_elapsed       | 107        |\n",
            "|    total_timesteps    | 26000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -21.7      |\n",
            "|    explained_variance | 0.000385   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5199       |\n",
            "|    policy_loss        | 2.25       |\n",
            "|    reward             | 0.55412763 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 0.234      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 241        |\n",
            "|    iterations         | 5300       |\n",
            "|    time_elapsed       | 109        |\n",
            "|    total_timesteps    | 26500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -21.7      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5299       |\n",
            "|    policy_loss        | -51.8      |\n",
            "|    reward             | -1.1033877 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 10.4       |\n",
            "--------------------------------------\n",
            "Episode: 35\n",
            "day: 1112, episode: 35\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1045888.73\n",
            "total_reward: 45888.73\n",
            "total_cost: 54739.27\n",
            "total_trades: 16677\n",
            "Sharpe: 0.190\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 241        |\n",
            "|    iterations         | 5400       |\n",
            "|    time_elapsed       | 111        |\n",
            "|    total_timesteps    | 27000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -21.7      |\n",
            "|    explained_variance | -0.011     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5399       |\n",
            "|    policy_loss        | 24.7       |\n",
            "|    reward             | 0.15243596 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 2.49       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 241       |\n",
            "|    iterations         | 5500      |\n",
            "|    time_elapsed       | 113       |\n",
            "|    total_timesteps    | 27500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -21.7     |\n",
            "|    explained_variance | 0.0326    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5499      |\n",
            "|    policy_loss        | 30.9      |\n",
            "|    reward             | -2.938769 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 4.05      |\n",
            "-------------------------------------\n",
            "Episode: 36\n",
            "day: 1112, episode: 36\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1183880.36\n",
            "total_reward: 183880.36\n",
            "total_cost: 69766.64\n",
            "total_trades: 16674\n",
            "Sharpe: 0.295\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 241       |\n",
            "|    iterations         | 5600      |\n",
            "|    time_elapsed       | 116       |\n",
            "|    total_timesteps    | 28000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -21.8     |\n",
            "|    explained_variance | 0.0681    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5599      |\n",
            "|    policy_loss        | -42.8     |\n",
            "|    reward             | 2.8964598 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 7.82      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 241       |\n",
            "|    iterations         | 5700      |\n",
            "|    time_elapsed       | 118       |\n",
            "|    total_timesteps    | 28500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -21.8     |\n",
            "|    explained_variance | -0.00905  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5699      |\n",
            "|    policy_loss        | 51.1      |\n",
            "|    reward             | 1.4617499 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 12.4      |\n",
            "-------------------------------------\n",
            "Episode: 37\n",
            "day: 1112, episode: 37\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1466201.61\n",
            "total_reward: 466201.61\n",
            "total_cost: 64320.39\n",
            "total_trades: 16672\n",
            "Sharpe: 0.425\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 241        |\n",
            "|    iterations         | 5800       |\n",
            "|    time_elapsed       | 120        |\n",
            "|    total_timesteps    | 29000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -21.8      |\n",
            "|    explained_variance | -0.00422   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5799       |\n",
            "|    policy_loss        | 62.2       |\n",
            "|    reward             | -1.0605353 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 17.1       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 241        |\n",
            "|    iterations         | 5900       |\n",
            "|    time_elapsed       | 122        |\n",
            "|    total_timesteps    | 29500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -21.8      |\n",
            "|    explained_variance | 0.0639     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5899       |\n",
            "|    policy_loss        | 52.5       |\n",
            "|    reward             | -1.0755574 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 7.3        |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 241          |\n",
            "|    iterations         | 6000         |\n",
            "|    time_elapsed       | 124          |\n",
            "|    total_timesteps    | 30000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -21.9        |\n",
            "|    explained_variance | -0.0229      |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5999         |\n",
            "|    policy_loss        | -54.6        |\n",
            "|    reward             | -0.076917104 |\n",
            "|    std                | 1.04         |\n",
            "|    value_loss         | 13           |\n",
            "----------------------------------------\n",
            "Episode: 38\n",
            "day: 1112, episode: 38\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1501477.52\n",
            "total_reward: 501477.52\n",
            "total_cost: 55184.48\n",
            "total_trades: 16676\n",
            "Sharpe: 0.439\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 241        |\n",
            "|    iterations         | 6100       |\n",
            "|    time_elapsed       | 126        |\n",
            "|    total_timesteps    | 30500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -21.9      |\n",
            "|    explained_variance | 0.0975     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6099       |\n",
            "|    policy_loss        | -50.8      |\n",
            "|    reward             | -0.4812304 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 5.22       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 241       |\n",
            "|    iterations         | 6200      |\n",
            "|    time_elapsed       | 128       |\n",
            "|    total_timesteps    | 31000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -21.9     |\n",
            "|    explained_variance | 0.15      |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6199      |\n",
            "|    policy_loss        | -9.12     |\n",
            "|    reward             | 3.5098653 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 2.78      |\n",
            "-------------------------------------\n",
            "Episode: 39\n",
            "day: 1112, episode: 39\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1426594.15\n",
            "total_reward: 426594.15\n",
            "total_cost: 78575.85\n",
            "total_trades: 16675\n",
            "Sharpe: 0.408\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 241        |\n",
            "|    iterations         | 6300       |\n",
            "|    time_elapsed       | 130        |\n",
            "|    total_timesteps    | 31500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -21.9      |\n",
            "|    explained_variance | -3.56      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6299       |\n",
            "|    policy_loss        | -0.961     |\n",
            "|    reward             | -0.2890849 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 0.115      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 241        |\n",
            "|    iterations         | 6400       |\n",
            "|    time_elapsed       | 132        |\n",
            "|    total_timesteps    | 32000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -21.9      |\n",
            "|    explained_variance | 0.0332     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6399       |\n",
            "|    policy_loss        | 72.6       |\n",
            "|    reward             | -1.0264957 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 12.1       |\n",
            "--------------------------------------\n",
            "Episode: 40\n",
            "day: 1112, episode: 40\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 476475.18\n",
            "total_reward: -523524.82\n",
            "total_cost: 78162.82\n",
            "total_trades: 16674\n",
            "Sharpe: -0.055\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 241        |\n",
            "|    iterations         | 6500       |\n",
            "|    time_elapsed       | 134        |\n",
            "|    total_timesteps    | 32500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -22        |\n",
            "|    explained_variance | 0.0456     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6499       |\n",
            "|    policy_loss        | 6.29       |\n",
            "|    reward             | -2.7645295 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 1.9        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 241       |\n",
            "|    iterations         | 6600      |\n",
            "|    time_elapsed       | 136       |\n",
            "|    total_timesteps    | 33000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -22       |\n",
            "|    explained_variance | -0.0041   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6599      |\n",
            "|    policy_loss        | -59.1     |\n",
            "|    reward             | 0.7839271 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 17.1      |\n",
            "-------------------------------------\n",
            "Episode: 41\n",
            "day: 1112, episode: 41\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1851615.76\n",
            "total_reward: 851615.76\n",
            "total_cost: 99163.24\n",
            "total_trades: 16678\n",
            "Sharpe: 0.573\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 241       |\n",
            "|    iterations         | 6700      |\n",
            "|    time_elapsed       | 138       |\n",
            "|    total_timesteps    | 33500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -22       |\n",
            "|    explained_variance | 0.65      |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6699      |\n",
            "|    policy_loss        | -113      |\n",
            "|    reward             | 2.1288087 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 25.3      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 241        |\n",
            "|    iterations         | 6800       |\n",
            "|    time_elapsed       | 140        |\n",
            "|    total_timesteps    | 34000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -22.1      |\n",
            "|    explained_variance | -0.799     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6799       |\n",
            "|    policy_loss        | -31.5      |\n",
            "|    reward             | 0.22091949 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 2.54       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 241         |\n",
            "|    iterations         | 6900        |\n",
            "|    time_elapsed       | 142         |\n",
            "|    total_timesteps    | 34500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -22.1       |\n",
            "|    explained_variance | -0.113      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6899        |\n",
            "|    policy_loss        | 5.26        |\n",
            "|    reward             | -0.18549353 |\n",
            "|    std                | 1.06        |\n",
            "|    value_loss         | 0.444       |\n",
            "---------------------------------------\n",
            "Episode: 42\n",
            "day: 1112, episode: 42\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 720810.70\n",
            "total_reward: -279189.30\n",
            "total_cost: 72394.30\n",
            "total_trades: 16675\n",
            "Sharpe: 0.099\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 241       |\n",
            "|    iterations         | 7000      |\n",
            "|    time_elapsed       | 145       |\n",
            "|    total_timesteps    | 35000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -22.1     |\n",
            "|    explained_variance | -0.109    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6999      |\n",
            "|    policy_loss        | -28.1     |\n",
            "|    reward             | 0.7332911 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 2.49      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 241       |\n",
            "|    iterations         | 7100      |\n",
            "|    time_elapsed       | 147       |\n",
            "|    total_timesteps    | 35500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -22.1     |\n",
            "|    explained_variance | 0.0755    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 7099      |\n",
            "|    policy_loss        | -18.7     |\n",
            "|    reward             | 4.0186872 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 7.08      |\n",
            "-------------------------------------\n",
            "Episode: 43\n",
            "day: 1112, episode: 43\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1398182.60\n",
            "total_reward: 398182.60\n",
            "total_cost: 79516.40\n",
            "total_trades: 16675\n",
            "Sharpe: 0.396\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 241          |\n",
            "|    iterations         | 7200         |\n",
            "|    time_elapsed       | 149          |\n",
            "|    total_timesteps    | 36000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -22.1        |\n",
            "|    explained_variance | -0.33        |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7199         |\n",
            "|    policy_loss        | -6.51        |\n",
            "|    reward             | -0.009883001 |\n",
            "|    std                | 1.06         |\n",
            "|    value_loss         | 0.204        |\n",
            "----------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 241      |\n",
            "|    iterations         | 7300     |\n",
            "|    time_elapsed       | 151      |\n",
            "|    total_timesteps    | 36500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -22.2    |\n",
            "|    explained_variance | -0.00478 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 7299     |\n",
            "|    policy_loss        | 50.9     |\n",
            "|    reward             | 2.793739 |\n",
            "|    std                | 1.06     |\n",
            "|    value_loss         | 7.97     |\n",
            "------------------------------------\n",
            "Episode: 44\n",
            "day: 1112, episode: 44\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 600826.50\n",
            "total_reward: -399173.50\n",
            "total_cost: 77926.50\n",
            "total_trades: 16678\n",
            "Sharpe: 0.133\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 241       |\n",
            "|    iterations         | 7400      |\n",
            "|    time_elapsed       | 153       |\n",
            "|    total_timesteps    | 37000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -22.2     |\n",
            "|    explained_variance | 0.0186    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 7399      |\n",
            "|    policy_loss        | -3.51     |\n",
            "|    reward             | 1.4254856 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 0.285     |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 241      |\n",
            "|    iterations         | 7500     |\n",
            "|    time_elapsed       | 155      |\n",
            "|    total_timesteps    | 37500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -22.2    |\n",
            "|    explained_variance | -0.0104  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 7499     |\n",
            "|    policy_loss        | 24.3     |\n",
            "|    reward             | 4.622466 |\n",
            "|    std                | 1.06     |\n",
            "|    value_loss         | 3.63     |\n",
            "------------------------------------\n",
            "Episode: 45\n",
            "day: 1112, episode: 45\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1564982.73\n",
            "total_reward: 564982.73\n",
            "total_cost: 84114.27\n",
            "total_trades: 16676\n",
            "Sharpe: 0.468\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 241       |\n",
            "|    iterations         | 7600      |\n",
            "|    time_elapsed       | 157       |\n",
            "|    total_timesteps    | 38000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -22.2     |\n",
            "|    explained_variance | 0.00967   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 7599      |\n",
            "|    policy_loss        | -170      |\n",
            "|    reward             | 1.3509696 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 71        |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 241        |\n",
            "|    iterations         | 7700       |\n",
            "|    time_elapsed       | 159        |\n",
            "|    total_timesteps    | 38500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -22.2      |\n",
            "|    explained_variance | -0.00654   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7699       |\n",
            "|    policy_loss        | 38.4       |\n",
            "|    reward             | 0.61605316 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 5.05       |\n",
            "--------------------------------------\n",
            "Episode: 46\n",
            "day: 1112, episode: 46\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1095522.52\n",
            "total_reward: 95522.52\n",
            "total_cost: 61225.48\n",
            "total_trades: 16675\n",
            "Sharpe: 0.238\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 242        |\n",
            "|    iterations         | 7800       |\n",
            "|    time_elapsed       | 161        |\n",
            "|    total_timesteps    | 39000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -22.2      |\n",
            "|    explained_variance | -0.0942    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7799       |\n",
            "|    policy_loss        | 8.72       |\n",
            "|    reward             | -1.5902064 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 0.977      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 242        |\n",
            "|    iterations         | 7900       |\n",
            "|    time_elapsed       | 163        |\n",
            "|    total_timesteps    | 39500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -22.2      |\n",
            "|    explained_variance | -1.12      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7899       |\n",
            "|    policy_loss        | 7.73       |\n",
            "|    reward             | 0.30307877 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 0.12       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 242       |\n",
            "|    iterations         | 8000      |\n",
            "|    time_elapsed       | 165       |\n",
            "|    total_timesteps    | 40000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -22.2     |\n",
            "|    explained_variance | 0.0763    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 7999      |\n",
            "|    policy_loss        | 10.2      |\n",
            "|    reward             | 1.3091534 |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 2.45      |\n",
            "-------------------------------------\n",
            "Episode: 47\n",
            "day: 1112, episode: 47\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1261810.19\n",
            "total_reward: 261810.19\n",
            "total_cost: 71173.81\n",
            "total_trades: 16674\n",
            "Sharpe: 0.332\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 242       |\n",
            "|    iterations         | 8100      |\n",
            "|    time_elapsed       | 167       |\n",
            "|    total_timesteps    | 40500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -22.2     |\n",
            "|    explained_variance | -0.0688   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8099      |\n",
            "|    policy_loss        | 34.7      |\n",
            "|    reward             | 0.4635085 |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 4.17      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 241        |\n",
            "|    iterations         | 8200       |\n",
            "|    time_elapsed       | 169        |\n",
            "|    total_timesteps    | 41000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -22.2      |\n",
            "|    explained_variance | -0.127     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8199       |\n",
            "|    policy_loss        | -88.8      |\n",
            "|    reward             | -2.1892762 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 17.9       |\n",
            "--------------------------------------\n",
            "Episode: 48\n",
            "day: 1112, episode: 48\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1277660.51\n",
            "total_reward: 277660.51\n",
            "total_cost: 65861.49\n",
            "total_trades: 16671\n",
            "Sharpe: 0.341\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 241         |\n",
            "|    iterations         | 8300        |\n",
            "|    time_elapsed       | 171         |\n",
            "|    total_timesteps    | 41500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -22.2       |\n",
            "|    explained_variance | -0.0755     |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8299        |\n",
            "|    policy_loss        | -22.5       |\n",
            "|    reward             | -0.10433925 |\n",
            "|    std                | 1.06        |\n",
            "|    value_loss         | 1.22        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 241         |\n",
            "|    iterations         | 8400        |\n",
            "|    time_elapsed       | 173         |\n",
            "|    total_timesteps    | 42000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -22.3       |\n",
            "|    explained_variance | -0.0394     |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8399        |\n",
            "|    policy_loss        | 67.8        |\n",
            "|    reward             | -0.40242904 |\n",
            "|    std                | 1.07        |\n",
            "|    value_loss         | 17.3        |\n",
            "---------------------------------------\n",
            "Episode: 49\n",
            "day: 1112, episode: 49\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 799815.66\n",
            "total_reward: -200184.34\n",
            "total_cost: 68632.34\n",
            "total_trades: 16679\n",
            "Sharpe: 0.076\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 241         |\n",
            "|    iterations         | 8500        |\n",
            "|    time_elapsed       | 175         |\n",
            "|    total_timesteps    | 42500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -22.3       |\n",
            "|    explained_variance | 0.0337      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8499        |\n",
            "|    policy_loss        | 16.6        |\n",
            "|    reward             | -0.99479425 |\n",
            "|    std                | 1.07        |\n",
            "|    value_loss         | 2.73        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 241        |\n",
            "|    iterations         | 8600       |\n",
            "|    time_elapsed       | 177        |\n",
            "|    total_timesteps    | 43000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -22.3      |\n",
            "|    explained_variance | 0.0467     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8599       |\n",
            "|    policy_loss        | 20.3       |\n",
            "|    reward             | -1.9225081 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 2.02       |\n",
            "--------------------------------------\n",
            "Episode: 50\n",
            "day: 1112, episode: 50\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1386600.30\n",
            "total_reward: 386600.30\n",
            "total_cost: 85194.70\n",
            "total_trades: 16678\n",
            "Sharpe: 0.392\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 241        |\n",
            "|    iterations         | 8700       |\n",
            "|    time_elapsed       | 179        |\n",
            "|    total_timesteps    | 43500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -22.3      |\n",
            "|    explained_variance | 0.0324     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8699       |\n",
            "|    policy_loss        | 118        |\n",
            "|    reward             | -11.669185 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 33.8       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 241        |\n",
            "|    iterations         | 8800       |\n",
            "|    time_elapsed       | 181        |\n",
            "|    total_timesteps    | 44000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -22.3      |\n",
            "|    explained_variance | 0.118      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8799       |\n",
            "|    policy_loss        | 48.3       |\n",
            "|    reward             | 0.06142468 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 8.04       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 241        |\n",
            "|    iterations         | 8900       |\n",
            "|    time_elapsed       | 183        |\n",
            "|    total_timesteps    | 44500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -22.3      |\n",
            "|    explained_variance | 0.408      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8899       |\n",
            "|    policy_loss        | 14.5       |\n",
            "|    reward             | -3.4698105 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 0.509      |\n",
            "--------------------------------------\n",
            "Episode: 51\n",
            "day: 1112, episode: 51\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1293779.12\n",
            "total_reward: 293779.12\n",
            "total_cost: 82795.88\n",
            "total_trades: 16676\n",
            "Sharpe: 0.345\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 241      |\n",
            "|    iterations         | 9000     |\n",
            "|    time_elapsed       | 186      |\n",
            "|    total_timesteps    | 45000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -22.3    |\n",
            "|    explained_variance | -0.0575  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 8999     |\n",
            "|    policy_loss        | -21.2    |\n",
            "|    reward             | 0.581877 |\n",
            "|    std                | 1.07     |\n",
            "|    value_loss         | 1.7      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 242      |\n",
            "|    iterations         | 9100     |\n",
            "|    time_elapsed       | 188      |\n",
            "|    total_timesteps    | 45500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -22.3    |\n",
            "|    explained_variance | -0.182   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 9099     |\n",
            "|    policy_loss        | -2.07    |\n",
            "|    reward             | -2.94732 |\n",
            "|    std                | 1.07     |\n",
            "|    value_loss         | 4.61     |\n",
            "------------------------------------\n",
            "Episode: 52\n",
            "day: 1112, episode: 52\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1586408.84\n",
            "total_reward: 586408.84\n",
            "total_cost: 77611.16\n",
            "total_trades: 16670\n",
            "Sharpe: 0.482\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 241       |\n",
            "|    iterations         | 9200      |\n",
            "|    time_elapsed       | 190       |\n",
            "|    total_timesteps    | 46000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -22.4     |\n",
            "|    explained_variance | -1.43     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9199      |\n",
            "|    policy_loss        | 17.8      |\n",
            "|    reward             | 2.3569686 |\n",
            "|    std                | 1.08      |\n",
            "|    value_loss         | 0.743     |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 241         |\n",
            "|    iterations         | 9300        |\n",
            "|    time_elapsed       | 192         |\n",
            "|    total_timesteps    | 46500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -22.4       |\n",
            "|    explained_variance | -0.131      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9299        |\n",
            "|    policy_loss        | -11.8       |\n",
            "|    reward             | -0.31335056 |\n",
            "|    std                | 1.07        |\n",
            "|    value_loss         | 4.55        |\n",
            "---------------------------------------\n",
            "Episode: 53\n",
            "day: 1112, episode: 53\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1541023.35\n",
            "total_reward: 541023.35\n",
            "total_cost: 66428.65\n",
            "total_trades: 16672\n",
            "Sharpe: 0.459\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 241        |\n",
            "|    iterations         | 9400       |\n",
            "|    time_elapsed       | 194        |\n",
            "|    total_timesteps    | 47000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -22.4      |\n",
            "|    explained_variance | -0.0205    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9399       |\n",
            "|    policy_loss        | -51.5      |\n",
            "|    reward             | -2.5907032 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 11.2       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 241        |\n",
            "|    iterations         | 9500       |\n",
            "|    time_elapsed       | 196        |\n",
            "|    total_timesteps    | 47500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -22.4      |\n",
            "|    explained_variance | -0.0172    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9499       |\n",
            "|    policy_loss        | -101       |\n",
            "|    reward             | -7.4422593 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 24.9       |\n",
            "--------------------------------------\n",
            "Episode: 54\n",
            "day: 1112, episode: 54\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1223144.99\n",
            "total_reward: 223144.99\n",
            "total_cost: 78293.01\n",
            "total_trades: 16669\n",
            "Sharpe: 0.312\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 241      |\n",
            "|    iterations         | 9600     |\n",
            "|    time_elapsed       | 198      |\n",
            "|    total_timesteps    | 48000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -22.4    |\n",
            "|    explained_variance | 0.00348  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 9599     |\n",
            "|    policy_loss        | -16.8    |\n",
            "|    reward             | -2.32945 |\n",
            "|    std                | 1.07     |\n",
            "|    value_loss         | 27.7     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 241        |\n",
            "|    iterations         | 9700       |\n",
            "|    time_elapsed       | 200        |\n",
            "|    total_timesteps    | 48500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -22.4      |\n",
            "|    explained_variance | 0.0378     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9699       |\n",
            "|    policy_loss        | 8.55       |\n",
            "|    reward             | 0.49679536 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 1.84       |\n",
            "--------------------------------------\n",
            "Episode: 55\n",
            "day: 1112, episode: 55\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1292285.11\n",
            "total_reward: 292285.11\n",
            "total_cost: 93433.89\n",
            "total_trades: 16669\n",
            "Sharpe: 0.345\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 241          |\n",
            "|    iterations         | 9800         |\n",
            "|    time_elapsed       | 202          |\n",
            "|    total_timesteps    | 49000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -22.4        |\n",
            "|    explained_variance | -0.0646      |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9799         |\n",
            "|    policy_loss        | 14.9         |\n",
            "|    reward             | -0.023521164 |\n",
            "|    std                | 1.08         |\n",
            "|    value_loss         | 1.3          |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 241         |\n",
            "|    iterations         | 9900        |\n",
            "|    time_elapsed       | 204         |\n",
            "|    total_timesteps    | 49500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -22.4       |\n",
            "|    explained_variance | 0.00278     |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9899        |\n",
            "|    policy_loss        | -14.8       |\n",
            "|    reward             | -0.70955884 |\n",
            "|    std                | 1.08        |\n",
            "|    value_loss         | 0.908       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 241        |\n",
            "|    iterations         | 10000      |\n",
            "|    time_elapsed       | 206        |\n",
            "|    total_timesteps    | 50000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -22.3      |\n",
            "|    explained_variance | 0.056      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9999       |\n",
            "|    policy_loss        | 25.9       |\n",
            "|    reward             | -12.614292 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 4.95       |\n",
            "--------------------------------------\n"
          ]
        }
      ],
      "source": [
        "agent = DRLAgent(env=env_train)\n",
        "model_a2c = agent.get_model(\"a2c\")\n",
        "\n",
        "trained_a2c = agent.train_model(model=model_a2c, tb_log_name='a2c', total_timesteps=50000)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ArAnGULyVVfK",
      "metadata": {
        "id": "ArAnGULyVVfK"
      },
      "source": [
        "## Trade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TzU6JBAWVGPG",
      "metadata": {
        "id": "TzU6JBAWVGPG"
      },
      "outputs": [],
      "source": [
        "trade = p.data_split(p.dataframe, TRADE_START_DATE, TRADE_END_DATE)\n",
        "env_kwargs = { \"stock_dim\": stock_dimension, \"hmax\": 1000, \"initial_amount\": 1000000, \"buy_cost_pct\": 6.87e-5, \"sell_cost_pct\": 1.0687e-3, \"reward_scaling\": 1e-4, \"state_space\": state_space, \"action_space\": stock_dimension, \"tech_indicator_list\": config.INDICATORS, \"print_verbosity\": 1, \"initial_buy\": False, \"hundred_each_trade\": True }\n",
        "e_trade_gym = StockTradingEnv(df=trade, **env_kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdg8qypiVSOn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdg8qypiVSOn",
        "outputId": "af6f6967-7e06-41c5-850f-d0e2512ecd43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode: 2\n",
            "day: 103, episode: 2\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 952511.32\n",
            "total_reward: -47488.68\n",
            "total_cost: 68.68\n",
            "total_trades: 608\n",
            "Sharpe: -0.366\n",
            "=================================\n",
            "hit end!\n"
          ]
        }
      ],
      "source": [
        "df_account_value, df_actions = DRLAgent.DRL_prediction(model=trained_ddpg, environment=e_trade_gym)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ih4rdH3uVSo1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ih4rdH3uVSo1",
        "outputId": "291d8234-ee54-4ef2-a511-1e084a783f4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "df_actions:             600000.SH  600009.SH  600016.SH  600028.SH  600030.SH  600031.SH  \\\n",
            "date                                                                           \n",
            "2019-08-01          0          0       1000       1000          0       1000   \n",
            "2019-08-02          0          0       1000       1000          0       1000   \n",
            "2019-08-05          0          0       1000       1000          0       1000   \n",
            "2019-08-06          0          0       1000       1000          0       1000   \n",
            "2019-08-07          0          0       1000       1000          0       1000   \n",
            "...               ...        ...        ...        ...        ...        ...   \n",
            "2019-12-25          0          0          0          0          0          0   \n",
            "2019-12-26          0          0          0          0          0          0   \n",
            "2019-12-27          0          0          0          0          0          0   \n",
            "2019-12-30          0          0          0          0          0          0   \n",
            "2019-12-31          0          0          0          0          0          0   \n",
            "\n",
            "            600036.SH  600050.SH  600104.SH  600196.SH  600276.SH  600309.SH  \\\n",
            "date                                                                           \n",
            "2019-08-01       1000          0          0          0          0          0   \n",
            "2019-08-02       1000          0          0          0          0          0   \n",
            "2019-08-05       1000          0          0          0          0          0   \n",
            "2019-08-06       1000          0          0          0          0          0   \n",
            "2019-08-07       1000          0          0          0          0          0   \n",
            "...               ...        ...        ...        ...        ...        ...   \n",
            "2019-12-25          0          0          0          0          0          0   \n",
            "2019-12-26          0          0          0          0          0          0   \n",
            "2019-12-27          0          0          0          0          0          0   \n",
            "2019-12-30          0          0          0          0          0          0   \n",
            "2019-12-31          0          0          0          0          0          0   \n",
            "\n",
            "            600519.SH  600547.SH  600570.SH  \n",
            "date                                         \n",
            "2019-08-01          0       1000          0  \n",
            "2019-08-02          0       1000          0  \n",
            "2019-08-05          0       1000          0  \n",
            "2019-08-06          0       1000          0  \n",
            "2019-08-07          0       1000          0  \n",
            "...               ...        ...        ...  \n",
            "2019-12-25          0          0          0  \n",
            "2019-12-26          0          0          0  \n",
            "2019-12-27          0          0          0  \n",
            "2019-12-30          0          0          0  \n",
            "2019-12-31          0          0          0  \n",
            "\n",
            "[103 rows x 15 columns]\n"
          ]
        }
      ],
      "source": [
        "df_actions.to_csv(\"action.csv\", index=False)\n",
        "print(f\"df_actions: {df_actions}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "l7X1KIaVWUYp",
      "metadata": {
        "id": "l7X1KIaVWUYp"
      },
      "source": [
        "## Backtest"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dUJn8einWPKI",
      "metadata": {
        "id": "dUJn8einWPKI"
      },
      "source": [
        "### matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pR6hNouKWOoY",
      "metadata": {
        "id": "pR6hNouKWOoY"
      },
      "outputs": [],
      "source": [
        "plotter = ReturnPlotter(df_account_value, trade, TRADE_START_DATE, TRADE_END_DATE)\n",
        "plotter.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Qx62Q575YC9I",
      "metadata": {
        "id": "Qx62Q575YC9I"
      },
      "outputs": [],
      "source": [
        "# ticket: SSE 50Ôºö000016\n",
        "plotter.plot(\"000016\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XUAh2S9Lamxe",
      "metadata": {
        "id": "XUAh2S9Lamxe"
      },
      "source": [
        "### CSI 300"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NJZdXMGvYI9O",
      "metadata": {
        "id": "NJZdXMGvYI9O"
      },
      "outputs": [],
      "source": [
        "baseline_df = plotter.get_baseline(\"399300\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZSRJpKINYcBa",
      "metadata": {
        "id": "ZSRJpKINYcBa"
      },
      "outputs": [],
      "source": [
        "daily_return = plotter.get_return(df_account_value)\n",
        "daily_return_base = plotter.get_return(baseline_df, value_col_name=\"close\")\n",
        "\n",
        "perf_func = timeseries.perf_stats\n",
        "perf_stats_all = perf_func(returns=daily_return, factor_returns=daily_return_base, positions=None, transactions=None, turnover_denom=\"AGB\")\n",
        "print(\"==============DRL Strategy Stats===========\")\n",
        "print(f\"perf_stats_all: {perf_stats_all}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6J0LpdE7YuQe",
      "metadata": {
        "id": "6J0LpdE7YuQe"
      },
      "outputs": [],
      "source": [
        "daily_return = plotter.get_return(df_account_value)\n",
        "daily_return_base = plotter.get_return(baseline_df, value_col_name=\"close\")\n",
        "\n",
        "perf_func = timeseries.perf_stats\n",
        "perf_stats_all = perf_func(returns=daily_return_base, factor_returns=daily_return_base, positions=None, transactions=None, turnover_denom=\"AGB\")\n",
        "\n",
        "print(\"==============Baseline Strategy Stats===========\")\n",
        "\n",
        "print(f\"perf_stats_all: {perf_stats_all}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "China_A_share_market_tushare.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "notify_time": "5",
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
